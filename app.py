#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import yaml
import subprocess
import threading
import time
import bcrypt
import secrets
from datetime import datetime, timedelta
from functools import wraps
from flask import Flask, render_template, request, jsonify, session, redirect, url_for, flash, send_file
from flask_socketio import SocketIO, emit
import logging
import zipfile
import tempfile
import uuid
import schedule
import psutil

app = Flask(__name__)
app.config['SECRET_KEY'] = 'your-secret-key-here'
socketio = SocketIO(app, cors_allowed_origins="*")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å…¨å±€å˜é‡å­˜å‚¨åŒæ­¥ä»»åŠ¡çŠ¶æ€
sync_tasks = {}

# ä»“åº“é…ç½®ç®¡ç†ç±»
class RegistryConfig:
    """ç§æœé…ç½®ç®¡ç†ç±»"""
    def __init__(self, config_file='config/registries.yaml'):
        self.config_file = config_file
        self.registries = self.load_config()
    
    def load_config(self):
        """åŠ è½½ç§æœé…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
                return config.get('registries', [])
        except FileNotFoundError:
            logger.warning(f"é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            return self.get_default_config()
        except Exception as e:
            logger.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return self.get_default_config()
    
    def get_default_config(self):
        """é»˜è®¤é…ç½®"""
        return [
            {
                'name': 'Harborç§æœ',
                'type': 'harbor',
                'url': 'harbor.example.com',
                'username': 'admin',
                'password': 'Harbor12345',
                'project': 'library'
            },
            {
                'name': 'é˜¿é‡Œäº‘ACR',
                'type': 'acr',
                'url': 'registry.cn-hangzhou.aliyuncs.com',
                'username': 'your-username',
                'password': 'your-password',
                'namespace': 'your-namespace'
            }
        ]

class UserManager:
    """ç”¨æˆ·ç®¡ç†ç±»"""
    def __init__(self, config_file='config/users.yaml'):
        self.config_file = config_file
        self.config = self.load_config()
        self.login_attempts = {}  # ç™»å½•å°è¯•è®°å½•
        
        # æ›´æ–°Flask secret key
        if self.config.get('session', {}).get('secret_key'):
            app.config['SECRET_KEY'] = self.config['session']['secret_key']
    
    def load_config(self):
        """åŠ è½½ç”¨æˆ·é…ç½®"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            logger.warning(f"ç”¨æˆ·é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨")
            return self.create_default_config()
        except Exception as e:
            logger.error(f"åŠ è½½ç”¨æˆ·é…ç½®å¤±è´¥: {e}")
            return self.create_default_config()
    
    def create_default_config(self):
        """åˆ›å»ºé»˜è®¤ç”¨æˆ·é…ç½®"""
        default_config = {
            'users': {
                'admin': {
                    'username': 'admin',
                    'password_hash': self.hash_password('admin123'),
                    'role': 'admin',
                    'display_name': 'ç®¡ç†å‘˜',
                    'active': True
                }
            },
            'session': {
                'secret_key': secrets.token_hex(32),
                'session_timeout': 3600,
                'remember_me_duration': 604800
            },
            'security': {
                'max_login_attempts': 5,
                'lockout_duration': 300,
                'password_min_length': 6
            }
        }
        
        # ä¿å­˜é»˜è®¤é…ç½®
        try:
            os.makedirs(os.path.dirname(self.config_file), exist_ok=True)
            with open(self.config_file, 'w', encoding='utf-8') as f:
                yaml.dump(default_config, f, allow_unicode=True, default_flow_style=False)
            logger.info(f"å·²åˆ›å»ºé»˜è®¤ç”¨æˆ·é…ç½®æ–‡ä»¶: {self.config_file}")
        except Exception as e:
            logger.error(f"åˆ›å»ºç”¨æˆ·é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        return default_config
    
    def hash_password(self, password):
        """å“ˆå¸Œå¯†ç """
        return bcrypt.hashpw(password.encode('utf-8'), bcrypt.gensalt()).decode('utf-8')
    
    def verify_password(self, password, password_hash):
        """éªŒè¯å¯†ç """
        try:
            return bcrypt.checkpw(password.encode('utf-8'), password_hash.encode('utf-8'))
        except Exception as e:
            logger.error(f"å¯†ç éªŒè¯å¤±è´¥: {e}")
            return False
    
    def get_user(self, username):
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        users = self.config.get('users', {})
        return users.get(username)
    
    def authenticate(self, username, password, request_ip=None):
        """ç”¨æˆ·è®¤è¯"""
        # æ£€æŸ¥è´¦æˆ·é”å®š
        if self.is_account_locked(username, request_ip):
            return False, "è´¦æˆ·å·²è¢«é”å®šï¼Œè¯·ç¨åå†è¯•"
        
        user = self.get_user(username)
        if not user:
            self.record_login_attempt(username, request_ip, False)
            return False, "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"
        
        if not user.get('active', True):
            return False, "è´¦æˆ·å·²è¢«ç¦ç”¨"
        
        if self.verify_password(password, user['password_hash']):
            # ç™»å½•æˆåŠŸï¼Œæ¸…é™¤ç™»å½•å°è¯•è®°å½•
            self.clear_login_attempts(username, request_ip)
            self.update_last_login(username)
            return True, "ç™»å½•æˆåŠŸ"
        else:
            self.record_login_attempt(username, request_ip, False)
            return False, "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"
    
    def is_account_locked(self, username, request_ip):
        """æ£€æŸ¥è´¦æˆ·æ˜¯å¦è¢«é”å®š"""
        key = f"{username}:{request_ip}" if request_ip else username
        attempts = self.login_attempts.get(key, [])
        
        security_config = self.config.get('security', {})
        max_attempts = security_config.get('max_login_attempts', 5)
        lockout_duration = security_config.get('lockout_duration', 300)
        
        if len(attempts) >= max_attempts:
            last_attempt = attempts[-1]
            if datetime.now() - last_attempt < timedelta(seconds=lockout_duration):
                return True
        
        return False
    
    def record_login_attempt(self, username, request_ip, success):
        """è®°å½•ç™»å½•å°è¯•"""
        key = f"{username}:{request_ip}" if request_ip else username
        
        if success:
            # æˆåŠŸç™»å½•ï¼Œæ¸…é™¤è®°å½•
            self.login_attempts.pop(key, None)
        else:
            # å¤±è´¥ç™»å½•ï¼Œè®°å½•æ—¶é—´
            if key not in self.login_attempts:
                self.login_attempts[key] = []
            self.login_attempts[key].append(datetime.now())
            
            # åªä¿ç•™æœ€è¿‘çš„å°è¯•è®°å½•
            security_config = self.config.get('security', {})
            max_attempts = security_config.get('max_login_attempts', 5)
            self.login_attempts[key] = self.login_attempts[key][-max_attempts:]
    
    def clear_login_attempts(self, username, request_ip):
        """æ¸…é™¤ç™»å½•å°è¯•è®°å½•"""
        key = f"{username}:{request_ip}" if request_ip else username
        self.login_attempts.pop(key, None)
    
    def update_last_login(self, username):
        """æ›´æ–°æœ€åç™»å½•æ—¶é—´"""
        try:
            self.config['users'][username]['last_login'] = datetime.now().isoformat()
            with open(self.config_file, 'w', encoding='utf-8') as f:
                yaml.dump(self.config, f, allow_unicode=True, default_flow_style=False)
        except Exception as e:
            logger.error(f"æ›´æ–°æœ€åç™»å½•æ—¶é—´å¤±è´¥: {e}")
    
    def is_session_valid(self, session_data):
        """æ£€æŸ¥ä¼šè¯æ˜¯å¦æœ‰æ•ˆ"""
        if not session_data:
            return False
        
        username = session_data.get('username')
        login_time = session_data.get('login_time')
        
        if not username or not login_time:
            return False
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨ä¸”æ´»è·ƒ
        user = self.get_user(username)
        if not user or not user.get('active', True):
            return False
        
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦è¿‡æœŸ
        session_config = self.config.get('session', {})
        session_timeout = session_config.get('session_timeout', 3600)
        
        try:
            login_datetime = datetime.fromisoformat(login_time)
            if datetime.now() - login_datetime > timedelta(seconds=session_timeout):
                return False
        except Exception:
            return False
        
        return True

def login_required(f):
    """ç™»å½•è£…é¥°å™¨"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not user_manager.is_session_valid(session):
            if request.is_json:
                return jsonify({'error': 'éœ€è¦ç™»å½•', 'redirect': '/login'}), 401
            return redirect(url_for('login'))
        return f(*args, **kwargs)
    return decorated_function

def admin_required(f):
    """ç®¡ç†å‘˜æƒé™è£…é¥°å™¨"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        if not user_manager.is_session_valid(session):
            if request.is_json:
                return jsonify({'error': 'éœ€è¦ç™»å½•', 'redirect': '/login'}), 401
            return redirect(url_for('login'))
        
        username = session.get('username')
        user = user_manager.get_user(username)
        
        if not user or user.get('role') != 'admin':
            if request.is_json:
                return jsonify({'error': 'éœ€è¦ç®¡ç†å‘˜æƒé™'}), 403
            return render_template('error.html', 
                                 error_code=403, 
                                 error_message='éœ€è¦ç®¡ç†å‘˜æƒé™æ‰èƒ½è®¿é—®æ­¤é¡µé¢')
        
        return f(*args, **kwargs)
    return decorated_function

# åˆ›å»ºç”¨æˆ·ç®¡ç†å®ä¾‹
user_manager = UserManager()
# åˆ›å»ºä»“åº“é…ç½®ç®¡ç†å®ä¾‹
registry_config = RegistryConfig()

class ImageSyncer:
    """é•œåƒåŒæ­¥ç±»"""
    def __init__(self, registry_config):
        self.registry_config = registry_config
        self.current_task_id = None
    
    def check_skopeo(self):
        """æ£€æŸ¥Skopeoæ˜¯å¦å®‰è£…"""
        try:
            result = subprocess.run(['skopeo', '--version'], capture_output=True, text=True)
            return result.returncode == 0
        except FileNotFoundError:
            return False
    
    def sync_images(self, task_id, images, target_registry, replace_level, source_auth=None, proxy_config=None, target_project=None):
        """åŒæ­¥é•œåƒåˆ—è¡¨"""
        self.current_task_id = task_id
        sync_tasks[task_id] = {
            'status': 'running',
            'progress': 0,
            'total': len(images),
            'current_image': '',
            'logs': [],
            'start_time': datetime.now(),
            'errors': []
        }
        
        try:
            # æ£€æŸ¥Skopeoæ˜¯å¦å®‰è£…
            if not self.check_skopeo():
                self.emit_log(task_id, "é”™è¯¯: Skopeoå·¥å…·æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Skopeo", "error")
                sync_tasks[task_id]['status'] = 'failed'
                return
            
            registry = next((r for r in self.registry_config.registries if r['name'] == target_registry), None)
            if not registry:
                self.emit_log(task_id, f"é”™è¯¯: æ‰¾ä¸åˆ°ç§æœé…ç½® {target_registry}", "error")
                sync_tasks[task_id]['status'] = 'failed'
                return
            
            self.emit_log(task_id, f"å¼€å§‹åŒæ­¥ {len(images)} ä¸ªé•œåƒåˆ° {target_registry}")
            
            # å¦‚æœé…ç½®äº†æºè®¤è¯ä¿¡æ¯ï¼Œè®°å½•æ—¥å¿—
            if source_auth:
                self.emit_log(task_id, f"å·²é…ç½®æºä»“åº“è®¤è¯ä¿¡æ¯ï¼Œç”¨æˆ·å: {source_auth['username']}")
            
            # å¦‚æœé…ç½®äº†ä»£ç†ï¼Œè®°å½•æ—¥å¿—
            if proxy_config:
                http_proxy = proxy_config.get('http_proxy', '')
                https_proxy = proxy_config.get('https_proxy', '')
                self.emit_log(task_id, f"å·²é…ç½®ç½‘ç»œä»£ç† - HTTP: {http_proxy}, HTTPS: {https_proxy}")
                if proxy_config.get('no_proxy'):
                    self.emit_log(task_id, f"ä¸ä½¿ç”¨ä»£ç†çš„åœ°å€: {proxy_config['no_proxy']}")
            
            for i, image in enumerate(images):
                if sync_tasks[task_id]['status'] == 'cancelled':
                    self.emit_log(task_id, "åŒæ­¥ä»»åŠ¡å·²å–æ¶ˆ")
                    return
                
                sync_tasks[task_id]['current_image'] = image
                self.emit_log(task_id, f"æ­£åœ¨åŒæ­¥é•œåƒ ({i+1}/{len(images)}): {image}")
                
                target_image = self.sync_single_image(task_id, image, registry, replace_level, source_auth, proxy_config, target_project)
                
                if target_image:
                    self.emit_log(task_id, f"ğŸ“‹ åŒæ­¥ä»»åŠ¡å®Œæˆ: {image}", "success")
                    self.emit_log(task_id, f"   â¤ ç›®æ ‡åœ°å€: {target_image}", "success")
                else:
                    self.emit_log(task_id, f"âŒ é•œåƒ {image} åŒæ­¥å¤±è´¥", "error")
                    sync_tasks[task_id]['errors'].append(image)
                
                sync_tasks[task_id]['progress'] = i + 1
                self.emit_progress(task_id)
            
            sync_tasks[task_id]['status'] = 'completed'
            sync_tasks[task_id]['end_time'] = datetime.now()
            
            error_count = len(sync_tasks[task_id]['errors'])
            if error_count == 0:
                self.emit_log(task_id, f"æ‰€æœ‰é•œåƒåŒæ­¥å®Œæˆï¼", "success")
            else:
                self.emit_log(task_id, f"åŒæ­¥å®Œæˆï¼Œä½†æœ‰ {error_count} ä¸ªé•œåƒå¤±è´¥", "warning")
        
        except Exception as e:
            self.emit_log(task_id, f"åŒæ­¥è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", "error")
            import traceback
            self.emit_log(task_id, f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}", "error")
            return False
    
    def sync_single_image(self, task_id, source_image, registry, replace_level, source_auth=None, proxy_config=None, target_project=None):
        """åŒæ­¥å•ä¸ªé•œåƒ"""
        try:
            self.emit_log(task_id, f"å¼€å§‹å¤„ç†é•œåƒ: {source_image}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ¬åœ°æ–‡ä»¶å¯¼å‡º
            if registry['type'] == 'local_file':
                return self.export_image_to_file(task_id, source_image, registry, replace_level, source_auth, proxy_config, target_project)
            
            # è·å–åŸºç¡€URLå’Œå‘½åç©ºé—´/é¡¹ç›®
            base_url = registry['url']
            
            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è¾“å…¥çš„ç›®æ ‡é¡¹ç›®/å‘½åç©ºé—´ï¼Œå¦åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
            if target_project:
                namespace = target_project
                self.emit_log(task_id, f"ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„é¡¹ç›®/å‘½åç©ºé—´: {namespace}")
            else:
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼
                if registry['type'] == 'harbor':
                    namespace = registry.get('project', 'library')
                elif registry['type'] == 'acr':
                    namespace = registry.get('namespace', 'default')
                elif registry['type'] == 'nexus':
                    namespace = registry.get('repository', 'docker-hosted')
                elif registry['type'] == 'swr':
                    namespace = registry.get('namespace', 'default')
                elif registry['type'] == 'tcr':
                    namespace = registry.get('namespace', 'default')
                else:
                    namespace = 'library'  # é»˜è®¤å‘½åç©ºé—´
                self.emit_log(task_id, f"ä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤é¡¹ç›®/å‘½åç©ºé—´: {namespace}")
            
            self.emit_log(task_id, f"ç§æœç±»å‹: {registry['type']}, æœ€ç»ˆå‘½åç©ºé—´: {namespace}")
            
            # åº”ç”¨æ›¿æ¢çº§åˆ«æ„å»ºç›®æ ‡é•œåƒåœ°å€
            target_image_path = self.apply_replace_level(source_image, namespace, replace_level)
            self.emit_log(task_id, f"æ›¿æ¢çº§åˆ«å¤„ç†ç»“æœ: {target_image_path}")
            
            # target_image_pathå·²ç»åŒ…å«äº†namespaceï¼Œæ‰€ä»¥ç›´æ¥ç”¨base_urlæ‹¼æ¥
            if target_image_path.startswith(namespace + '/'):
                # å¦‚æœå·²ç»åŒ…å«namespaceï¼Œç›´æ¥æ‹¼æ¥
                target_image = f"{base_url}/{target_image_path}"
            else:
                # å¦‚æœä¸åŒ…å«namespaceï¼Œéœ€è¦æ·»åŠ 
                target_image = f"{base_url}/{namespace}/{target_image_path}"
            
            self.emit_log(task_id, f"æœ€ç»ˆç›®æ ‡é•œåƒ: {target_image}")
            
            # æ„å»ºskopeoå‘½ä»¤
            cmd = ['skopeo', 'copy']
            
            # æ·»åŠ åŸºæœ¬å‚æ•°ï¼Œå…¼å®¹å½“å‰skopeoç‰ˆæœ¬
            cmd.extend(['--dest-tls-verify=false', '--src-tls-verify=false'])
            
            # æ·»åŠ ç½‘ç»œä¼˜åŒ–å‚æ•°ï¼ˆç§»é™¤ä¸æ”¯æŒçš„--retry-timesï¼‰
            cmd.extend([
                '--format', 'v2s2'     # ä½¿ç”¨è¾ƒæ–°çš„é•œåƒæ ¼å¼
            ])
            
            # å¯¹äºé˜¿é‡Œäº‘ACRï¼Œæ·»åŠ ç‰¹æ®Šå¤„ç†
            if 'aliyuncs.com' in registry['url']:
                self.emit_log(task_id, "æ£€æµ‹åˆ°é˜¿é‡Œäº‘ACRï¼Œå¯ç”¨ä¼˜åŒ–é…ç½®")
                # é˜¿é‡Œäº‘ACRå»ºè®®ä½¿ç”¨çš„å‚æ•°
                cmd.extend(['--dest-compress-format', 'gzip'])
            
            # æ·»åŠ æºè®¤è¯ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if source_auth and source_auth.get('username') and source_auth.get('password'):
                cmd.extend(['--src-creds', f"{source_auth['username']}:{source_auth['password']}"])
                self.emit_log(task_id, f"æ·»åŠ æºä»“åº“è®¤è¯ä¿¡æ¯ï¼Œç”¨æˆ·å: {source_auth['username']}")
            else:
                self.emit_log(task_id, "æºä»“åº“: å…¬å¼€è®¿é—®")
            
            # æ·»åŠ ç›®æ ‡è®¤è¯ä¿¡æ¯
            if registry.get('username') and registry.get('password'):
                cmd.extend(['--dest-creds', f"{registry['username']}:{registry['password']}"])
                self.emit_log(task_id, f"æ·»åŠ ç›®æ ‡ä»“åº“è®¤è¯ä¿¡æ¯ï¼Œç”¨æˆ·å: {registry['username']}")
            else:
                self.emit_log(task_id, "ç›®æ ‡ä»“åº“: æœªé…ç½®è®¤è¯ä¿¡æ¯")
            
            # æ·»åŠ æºå’Œç›®æ ‡åœ°å€
            cmd.extend([f'docker://{source_image}', f'docker://{target_image}'])
            
            # æ˜¾ç¤ºå®Œæ•´å‘½ä»¤ï¼ˆéšè—å¯†ç ï¼‰
            safe_cmd = cmd.copy()
            for i, part in enumerate(safe_cmd):
                if ('--dest-creds' in safe_cmd or '--src-creds' in safe_cmd) and i > 0:
                    if safe_cmd[i-1] in ['--dest-creds', '--src-creds']:
                        safe_cmd[i] = safe_cmd[i].split(':')[0] + ':***'
            self.emit_log(task_id, f"æ‰§è¡Œå‘½ä»¤: {' '.join(safe_cmd)}")
            
            # æ‰§è¡ŒåŒæ­¥å‘½ä»¤
            self.emit_log(task_id, "å¼€å§‹æ‰§è¡Œskopeoå‘½ä»¤...")
            try:
                # å‡†å¤‡ç¯å¢ƒå˜é‡
                env = os.environ.copy()
                
                # å¦‚æœé…ç½®äº†ä»£ç†ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡
                if proxy_config:
                    # æ™ºèƒ½å¤„ç†ä»£ç†æ’é™¤åˆ—è¡¨ï¼Œè‡ªåŠ¨æ·»åŠ ç›®æ ‡ç§æœåœ°å€
                    no_proxy_list = []
                    if proxy_config.get('no_proxy'):
                        no_proxy_list = [addr.strip() for addr in proxy_config['no_proxy'].split(',')]
                    
                    # è‡ªåŠ¨æ·»åŠ ç›®æ ‡ç§æœåœ°å€åˆ°æ’é™¤åˆ—è¡¨
                    target_registry_url = registry['url']
                    if target_registry_url not in no_proxy_list:
                        no_proxy_list.append(target_registry_url)
                        self.emit_log(task_id, f"è‡ªåŠ¨å°†ç›®æ ‡ç§æœæ·»åŠ åˆ°ä»£ç†æ’é™¤åˆ—è¡¨: {target_registry_url}")
                    
                    if proxy_config.get('http_proxy'):
                        env['HTTP_PROXY'] = proxy_config['http_proxy']
                        env['http_proxy'] = proxy_config['http_proxy']
                        self.emit_log(task_id, f"è®¾ç½®HTTPä»£ç†: {proxy_config['http_proxy']}")
                    
                    if proxy_config.get('https_proxy'):
                        env['HTTPS_PROXY'] = proxy_config['https_proxy']
                        env['https_proxy'] = proxy_config['https_proxy']
                        self.emit_log(task_id, f"è®¾ç½®HTTPSä»£ç†: {proxy_config['https_proxy']}")
                    
                    # è®¾ç½®æ›´æ–°åçš„æ’é™¤åˆ—è¡¨
                    if no_proxy_list:
                        no_proxy_str = ','.join(no_proxy_list)
                        env['NO_PROXY'] = no_proxy_str
                        env['no_proxy'] = no_proxy_str
                        self.emit_log(task_id, f"ä»£ç†æ’é™¤åˆ—è¡¨: {no_proxy_str}")
                
                process = subprocess.Popen(
                    cmd, 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.PIPE,  # åˆ†åˆ«å¤„ç†stderr
                    text=True,
                    universal_newlines=True,
                    env=env  # ä¼ é€’ç¯å¢ƒå˜é‡
                )
                
                # å¯¹äºé˜¿é‡Œäº‘ACRï¼Œä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´
                timeout_seconds = 300  # é»˜è®¤5åˆ†é’Ÿ
                if 'aliyuncs.com' in registry['url']:
                    timeout_seconds = 600  # é˜¿é‡Œäº‘ACRä½¿ç”¨10åˆ†é’Ÿè¶…æ—¶
                    self.emit_log(task_id, f"é˜¿é‡Œäº‘ACRåŒæ­¥ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´: {timeout_seconds}ç§’")
                
                # è®¾ç½®è¶…æ—¶
                stdout, stderr = process.communicate(timeout=timeout_seconds)
                
                # è¾“å‡ºæ ‡å‡†è¾“å‡º
                if stdout:
                    for line in stdout.strip().split('\n'):
                        if line.strip():
                            self.emit_log(task_id, f"  {line}")
                
                # è¾“å‡ºé”™è¯¯ä¿¡æ¯
                if stderr:
                    for line in stderr.strip().split('\n'):
                        if line.strip():
                            # åˆ¤æ–­æ˜¯å¦æ˜¯ç½‘ç»œç›¸å…³é”™è¯¯
                            if any(keyword in line.lower() for keyword in ['timeout', 'dial tcp', 'connection', 'network']):
                                self.emit_log(task_id, f"  ç½‘ç»œé”™è¯¯: {line}", "error")
                            else:
                                self.emit_log(task_id, f"  é”™è¯¯: {line}", "warning")
                
                self.emit_log(task_id, f"å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {process.returncode}")
                
                if process.returncode == 0:
                    self.emit_log(task_id, f"âœ… é•œåƒåŒæ­¥æˆåŠŸ", "success")
                    self.emit_log(task_id, f"   æºé•œåƒ: {source_image}", "info")
                    self.emit_log(task_id, f"   ç›®æ ‡é•œåƒ: {target_image}", "info")
                    return target_image  # è¿”å›ç›®æ ‡é•œåƒåœ°å€è€Œä¸æ˜¯True
                else:
                    # æ ¹æ®é”™è¯¯ç±»å‹ç»™å‡ºä¸åŒçš„æç¤º
                    if stderr and any(keyword in stderr.lower() for keyword in ['timeout', 'dial tcp', 'connection']):
                        self.emit_log(task_id, f"ç½‘ç»œè¿æ¥è¶…æ—¶æˆ–å¤±è´¥ï¼Œå¯èƒ½åŸå› ï¼š", "error")
                        self.emit_log(task_id, f"  1. æ— æ³•è®¿é—®æºé•œåƒä»“åº“ (å¦‚Docker Hubè¢«å¢™)", "error")
                        self.emit_log(task_id, f"  2. ç½‘ç»œè¿æ¥ä¸ç¨³å®š", "error")
                        self.emit_log(task_id, f"  3. å»ºè®®ä½¿ç”¨å›½å†…é•œåƒæºæˆ–æœ¬åœ°é•œåƒ", "error")
                    elif stderr and 'aliyuncs.com' in stderr and 'unexpected EOF' in stderr:
                        self.emit_log(task_id, f"é˜¿é‡Œäº‘ACRè®¤è¯è¿æ¥ä¸­æ–­ï¼Œå¯èƒ½åŸå› ï¼š", "error")
                        self.emit_log(task_id, f"  1. ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œè®¤è¯è¿‡ç¨‹ä¸­æ–­", "error")
                        self.emit_log(task_id, f"  2. é˜¿é‡Œäº‘ACRæœåŠ¡æš‚æ—¶ä¸å¯ç”¨", "error")
                        self.emit_log(task_id, f"  3. é•œåƒå±‚è¿‡å¤§ï¼Œä¼ è¾“è¶…æ—¶", "error")
                        self.emit_log(task_id, f"  4. å»ºè®®ï¼šç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥", "error")
                        self.emit_log(task_id, f"  5. ç¡®è®¤é˜¿é‡Œäº‘ACRè®¤è¯ä¿¡æ¯æ˜¯å¦æ­£ç¡®", "error")
                    elif stderr and 'aliyuncs.com' in stderr:
                        self.emit_log(task_id, f"é˜¿é‡Œäº‘ACRæ¨é€å¤±è´¥ï¼Œå»ºè®®æ£€æŸ¥ï¼š", "error")
                        self.emit_log(task_id, f"  1. è´¦å·æƒé™æ˜¯å¦è¶³å¤Ÿï¼ˆéœ€è¦pushæƒé™ï¼‰", "error")
                        self.emit_log(task_id, f"  2. å‘½åç©ºé—´æ˜¯å¦å­˜åœ¨ä¸”å¯è®¿é—®", "error")
                        self.emit_log(task_id, f"  3. ç½‘ç»œè¿æ¥æ˜¯å¦ç¨³å®š", "error")
                        self.emit_log(task_id, f"  4. è®¤è¯ä¿¡æ¯æ˜¯å¦æ­£ç¡®", "error")
                    else:
                        self.emit_log(task_id, f"skopeoå‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œè¿”å›ç : {process.returncode}", "error")
                    return False
                    
            except subprocess.TimeoutExpired:
                process.kill()
                self.emit_log(task_id, f"é•œåƒåŒæ­¥è¶…æ—¶(3åˆ†é’Ÿ)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥", "error")
                self.emit_log(task_id, f"å»ºè®®ï¼šä½¿ç”¨å›½å†…é•œåƒæºæˆ–æ£€æŸ¥ç½‘ç»œé…ç½®", "error")
                return False
        
        except Exception as e:
            self.emit_log(task_id, f"åŒæ­¥é•œåƒ {source_image} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}", "error")
            import traceback
            self.emit_log(task_id, f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}", "error")
            return False
    
    def apply_replace_level(self, source_image, namespace, replace_level):
        """æ ¹æ®æ›¿æ¢çº§åˆ«åº”ç”¨é•œåƒè·¯å¾„å˜æ¢"""
        # ç§»é™¤å¯èƒ½çš„registryå‰ç¼€ (å¦‚ docker.io/, gcr.io/ ç­‰)
        if '/' in source_image and '.' in source_image.split('/')[0]:
            # å¦‚æœç¬¬ä¸€éƒ¨åˆ†åŒ…å«ç‚¹ï¼Œå¯èƒ½æ˜¯registryåœ°å€ï¼Œå»é™¤å®ƒ
            parts = source_image.split('/')
            if len(parts) > 1 and ('.' in parts[0] or ':' in parts[0]):
                source_image = '/'.join(parts[1:])
        
        # åˆ†å‰²é•œåƒè·¯å¾„
        path_parts = source_image.split('/')
        
        if replace_level == 'all':
            # æ›¿æ¢æ‰€æœ‰çº§ï¼šåªä¿ç•™æœ€åçš„é•œåƒå
            image_name = path_parts[-1]
            return f"{namespace}/{image_name}"
        elif replace_level == 'none':
            # æ— æ›¿æ¢ï¼šä¿ç•™å®Œæ•´è·¯å¾„
            return f"{namespace}/{source_image}"
        elif replace_level in ['1', '2', '3']:
            # æ›¿æ¢æŒ‡å®šçº§åˆ«
            replace_count = int(replace_level)
            if len(path_parts) > replace_count:
                # å»é™¤å‰é¢çš„æŒ‡å®šçº§åˆ«
                remaining_parts = path_parts[replace_count:]
                remaining_path = '/'.join(remaining_parts)
                return f"{namespace}/{remaining_path}"
            else:
                # å¦‚æœè·¯å¾„çº§åˆ«ä¸å¤Ÿï¼Œåªä¿ç•™é•œåƒå
                image_name = path_parts[-1]
                return f"{namespace}/{image_name}"
        else:
            # é»˜è®¤å¤„ç†ï¼šæ›¿æ¢1çº§
            if len(path_parts) > 1:
                remaining_parts = path_parts[1:]
                remaining_path = '/'.join(remaining_parts)
                return f"{namespace}/{remaining_path}"
            else:
                return f"{namespace}/{source_image}"
    
    def image_exists(self, image, registry):
        """æ£€æŸ¥é•œåƒæ˜¯å¦å­˜åœ¨"""
        try:
            cmd = ['skopeo', 'inspect', f'docker://{image}']
            if registry.get('username') and registry.get('password'):
                cmd.extend(['--creds', f"{registry['username']}:{registry['password']}"])
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            return result.returncode == 0
        except:
            return False
    
    def emit_log(self, task_id, message, level="info"):
        """å‘é€æ—¥å¿—åˆ°å‰ç«¯"""
        log_entry = {
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'level': level,
            'message': message
        }
        sync_tasks[task_id]['logs'].append(log_entry)
        socketio.emit('sync_log', {'task_id': task_id, 'log': log_entry})
    
    def emit_progress(self, task_id):
        """å‘é€è¿›åº¦åˆ°å‰ç«¯"""
        task = sync_tasks[task_id]
        progress_data = {
            'task_id': task_id,
            'progress': task['progress'],
            'total': task['total'],
            'current_image': task['current_image'],
            'status': task['status']
        }
        socketio.emit('sync_progress', progress_data)

    def export_image_to_file(self, task_id, source_image, registry, replace_level, source_auth=None, proxy_config=None, target_project=None):
        """å¯¼å‡ºé•œåƒåˆ°æœ¬åœ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
            downloads_dir = registry['url']
            os.makedirs(downloads_dir, exist_ok=True)
            
            # ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
            safe_image_name = source_image.replace('/', '_').replace(':', '_')
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{safe_image_name}_{timestamp}.tar"
            file_path = os.path.join(downloads_dir, filename)
            
            self.emit_log(task_id, f"å¯¼å‡ºç±»å‹: æœ¬åœ°æ–‡ä»¶")
            self.emit_log(task_id, f"æ–‡ä»¶è·¯å¾„: {file_path}")
            
            # æ„å»ºskopeoå‘½ä»¤ - ä½¿ç”¨ä¿ç•™åç§°çš„æ ¼å¼
            cmd = ['skopeo', 'copy']
            
            # æ·»åŠ åŸºæœ¬å‚æ•°
            cmd.extend(['--src-tls-verify=false'])
            
            # æ·»åŠ æºè®¤è¯ä¿¡æ¯ï¼ˆå¦‚æœæä¾›ï¼‰
            if source_auth and source_auth.get('username') and source_auth.get('password'):
                cmd.extend(['--src-creds', f"{source_auth['username']}:{source_auth['password']}"])
                self.emit_log(task_id, f"æ·»åŠ æºä»“åº“è®¤è¯ä¿¡æ¯ï¼Œç”¨æˆ·å: {source_auth['username']}")
            else:
                self.emit_log(task_id, "æºä»“åº“: å…¬å¼€è®¿é—®")
            
            # ä½¿ç”¨docker-archiveæ ¼å¼ï¼Œä½†æŒ‡å®šç›®æ ‡é•œåƒåç§°æ¥ä¿ç•™æ ‡ç­¾
            # æ ¼å¼ï¼šdocker-archive:æ–‡ä»¶è·¯å¾„:é•œåƒå:æ ‡ç­¾
            if ':' in source_image:
                image_name, tag = source_image.rsplit(':', 1)
                # æ¸…ç†é•œåƒåç§°ä¸­çš„registryå‰ç¼€
                if '/' in image_name and '.' in image_name.split('/')[0]:
                    image_name = '/'.join(image_name.split('/')[1:])
                target_spec = f"docker-archive:{file_path}:{image_name}:{tag}"
            else:
                # æ²¡æœ‰æ ‡ç­¾çš„æƒ…å†µï¼Œä½¿ç”¨latest
                image_name = source_image
                if '/' in image_name and '.' in image_name.split('/')[0]:
                    image_name = '/'.join(image_name.split('/')[1:])
                target_spec = f"docker-archive:{file_path}:{image_name}:latest"
            
            cmd.extend([f'docker://{source_image}', target_spec])
            
            self.emit_log(task_id, f"ç›®æ ‡è§„æ ¼: {target_spec}")
            
            # æ˜¾ç¤ºå®Œæ•´å‘½ä»¤ï¼ˆéšè—å¯†ç ï¼‰
            safe_cmd = cmd.copy()
            for i, part in enumerate(safe_cmd):
                if '--src-creds' in safe_cmd and i > 0:
                    if safe_cmd[i-1] == '--src-creds':
                        safe_cmd[i] = safe_cmd[i].split(':')[0] + ':***'
            self.emit_log(task_id, f"æ‰§è¡Œå‘½ä»¤: {' '.join(safe_cmd)}")
            
            # æ‰§è¡Œå¯¼å‡ºå‘½ä»¤
            self.emit_log(task_id, "å¼€å§‹æ‰§è¡Œskopeoå¯¼å‡ºå‘½ä»¤...")
            try:
                # å‡†å¤‡ç¯å¢ƒå˜é‡
                env = os.environ.copy()
                
                # å¦‚æœé…ç½®äº†ä»£ç†ï¼Œè®¾ç½®ç¯å¢ƒå˜é‡
                if proxy_config:
                    if proxy_config.get('http_proxy'):
                        env['HTTP_PROXY'] = proxy_config['http_proxy']
                        env['http_proxy'] = proxy_config['http_proxy']
                        self.emit_log(task_id, f"è®¾ç½®HTTPä»£ç†: {proxy_config['http_proxy']}")
                    
                    if proxy_config.get('https_proxy'):
                        env['HTTPS_PROXY'] = proxy_config['https_proxy']
                        env['https_proxy'] = proxy_config['https_proxy']
                        self.emit_log(task_id, f"è®¾ç½®HTTPSä»£ç†: {proxy_config['https_proxy']}")
                    
                    if proxy_config.get('no_proxy'):
                        env['NO_PROXY'] = proxy_config['no_proxy']
                        env['no_proxy'] = proxy_config['no_proxy']
                        self.emit_log(task_id, f"ä»£ç†æ’é™¤åˆ—è¡¨: {proxy_config['no_proxy']}")
                
                process = subprocess.Popen(
                    cmd, 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.PIPE,
                    text=True,
                    universal_newlines=True,
                    env=env
                )
                
                # è®¾ç½®è¶…æ—¶æ—¶é—´ï¼ˆå¯¼å‡ºå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼‰
                timeout_seconds = 600  # 10åˆ†é’Ÿ
                self.emit_log(task_id, f"è®¾ç½®å¯¼å‡ºè¶…æ—¶æ—¶é—´: {timeout_seconds}ç§’")
                
                stdout, stderr = process.communicate(timeout=timeout_seconds)
                
                # è¾“å‡ºæ ‡å‡†è¾“å‡º
                if stdout:
                    for line in stdout.strip().split('\n'):
                        if line.strip():
                            self.emit_log(task_id, f"  {line}")
                
                # è¾“å‡ºé”™è¯¯ä¿¡æ¯
                if stderr:
                    for line in stderr.strip().split('\n'):
                        if line.strip():
                            self.emit_log(task_id, f"  {line}", "warning")
                
                self.emit_log(task_id, f"å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {process.returncode}")
                
                if process.returncode == 0:
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨å¹¶è·å–å¤§å°
                    if os.path.exists(file_path):
                        file_size = os.path.getsize(file_path)
                        file_size_mb = file_size / (1024 * 1024)
                        
                        self.emit_log(task_id, f"âœ… é•œåƒå¯¼å‡ºæˆåŠŸ", "success")
                        self.emit_log(task_id, f"   æºé•œåƒ: {source_image}", "info")
                        self.emit_log(task_id, f"   å¯¼å‡ºæ–‡ä»¶: {filename}", "info")
                        self.emit_log(task_id, f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB", "info")
                        
                        # ç”Ÿæˆä¸‹è½½é“¾æ¥å’Œæ ‡ç­¾è„šæœ¬
                        download_url = f"/downloads/{filename}"
                        
                        # æå–é•œåƒåç§°å’Œæ ‡ç­¾ç”¨äºç”Ÿæˆæ ‡è®°è„šæœ¬
                        if ':' in source_image:
                            final_image_name, final_tag = source_image.rsplit(':', 1)
                        else:
                            final_image_name, final_tag = source_image, 'latest'
                        
                        # æ¸…ç†é•œåƒåç§°ä¸­çš„registryå‰ç¼€
                        if '/' in final_image_name and '.' in final_image_name.split('/')[0]:
                            final_image_name = '/'.join(final_image_name.split('/')[1:])
                        
                        expected_name = f"{final_image_name}:{final_tag}"
                        
                        self.emit_log(task_id, f"   ä¸‹è½½åœ°å€: {download_url}", "success")
                        self.emit_log(task_id, f"   å¯¼å…¥å‘½ä»¤: docker load < {filename}", "info")
                        self.emit_log(task_id, f"   é¢„æœŸé•œåƒåç§°: {expected_name}", "info")
                        self.emit_log(task_id, f"   ğŸ’¡ å¦‚æœå¯¼å…¥åæ˜¾ç¤º<none>ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é‡æ–°æ ‡è®°:", "info")
                        self.emit_log(task_id, f"   docker tag <IMAGE_ID> {expected_name}", "info")
                        
                        # ç”Ÿæˆæ ‡è®°è„šæœ¬
                        script_name = f"tag_{safe_image_name}_{timestamp}.sh"
                        script_path = os.path.join(downloads_dir, script_name)
                        
                        tag_script_content = f"""#!/bin/bash
# é•œåƒæ ‡è®°è„šæœ¬ - è‡ªåŠ¨ç”Ÿæˆ
# æºé•œåƒ: {source_image}
# ç›®æ ‡åç§°: {expected_name}

echo "æ­£åœ¨ä¸ºå¯¼å…¥çš„é•œåƒè®¾ç½®æ­£ç¡®çš„æ ‡ç­¾..."

# é¦–å…ˆè½½å…¥é•œåƒ
echo "è½½å…¥é•œåƒæ–‡ä»¶: {filename}"

# æ–¹æ³•1: å°è¯•ä»docker loadè¾“å‡ºä¸­è·å–é•œåƒä¿¡æ¯
LOAD_OUTPUT=$(docker load < {filename} 2>&1)
echo "Docker load è¾“å‡º: $LOAD_OUTPUT"

# æå–é•œåƒIDæˆ–é•œåƒåï¼ˆä½¿ç”¨æ›´å…¼å®¹çš„æ–¹å¼ï¼‰
IMAGE_ID=""

# å°è¯•åŒ¹é… "Loaded image ID: sha256:xxxx" æ ¼å¼
if echo "$LOAD_OUTPUT" | grep -q "Loaded image ID:"; then
    IMAGE_ID=$(echo "$LOAD_OUTPUT" | sed -n 's/.*Loaded image ID: sha256:\\([a-f0-9]*\\).*/\\1/p')
    if [ -n "$IMAGE_ID" ]; then
        IMAGE_ID="sha256:$IMAGE_ID"
        echo "âœ… æ£€æµ‹åˆ°é•œåƒID: $IMAGE_ID"
    fi
fi

# å°è¯•åŒ¹é… "Loaded image: xxxx" æ ¼å¼
if [ -z "$IMAGE_ID" ] && echo "$LOAD_OUTPUT" | grep -q "Loaded image:"; then
    IMAGE_ID=$(echo "$LOAD_OUTPUT" | sed -n 's/.*Loaded image: \\(.*\\)/\\1/p')
    if [ -n "$IMAGE_ID" ]; then
        echo "âœ… æ£€æµ‹åˆ°é•œåƒå: $IMAGE_ID"
    fi
fi

# æ–¹æ³•2: å¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±è´¥ï¼Œå°è¯•æŸ¥æ‰¾æœ€è¿‘å¯¼å…¥çš„é•œåƒ
if [ -z "$IMAGE_ID" ]; then
    echo "âš ï¸ æ— æ³•ä»docker loadè¾“å‡ºä¸­è§£æé•œåƒä¿¡æ¯ï¼Œå°è¯•å…¶ä»–æ–¹æ³•..."
    
    # æŸ¥æ‰¾å¯èƒ½çš„å€™é€‰é•œåƒï¼ˆæœ€è¿‘åˆ›å»ºçš„ï¼Œæˆ–è€…åç§°åŒ¹é…çš„ï¼‰
    CANDIDATES=$(docker images --format "table {{{{.Repository}}}}:{{{{.Tag}}}}\\t{{{{.ID}}}}\\t{{{{.CreatedAt}}}}" | grep -E "({final_image_name}|<none>)" | head -5)
    
    if [ -n "$CANDIDATES" ]; then
        echo "æ‰¾åˆ°å¯èƒ½çš„å€™é€‰é•œåƒ:"
        echo "$CANDIDATES"
        echo ""
        
        # å°è¯•æ‰¾åˆ°<none>æ ‡ç­¾çš„é•œåƒ
        NONE_IMAGE=$(docker images --format "{{{{.ID}}}}" --filter "dangling=true" | head -1)
        if [ -n "$NONE_IMAGE" ]; then
            IMAGE_ID="$NONE_IMAGE"
            echo "âœ… æ‰¾åˆ°<none>æ ‡ç­¾é•œåƒ: $IMAGE_ID"
        else
            # å°è¯•æ‰¾åˆ°æœ€è¿‘çš„åŒ¹é…é•œåƒ
            RECENT_IMAGE=$(docker images --format "{{{{.ID}}}}" {final_image_name} 2>/dev/null | head -1)
            if [ -n "$RECENT_IMAGE" ]; then
                IMAGE_ID="$RECENT_IMAGE"
                echo "âœ… æ‰¾åˆ°å·²å­˜åœ¨çš„é•œåƒ: $IMAGE_ID"
            fi
        fi
    fi
fi

# æ–¹æ³•3: æœ€åçš„æ‰‹åŠ¨æç¤º
if [ -z "$IMAGE_ID" ]; then
    echo "âŒ æ— æ³•è‡ªåŠ¨è·å–é•œåƒIDï¼Œè¯·æ‰‹åŠ¨å¤„ç†ï¼š"
    echo ""
    echo "1. æŸ¥çœ‹æ‰€æœ‰é•œåƒ:"
    docker images
    echo ""
    echo "2. æ‰¾åˆ°åˆšå¯¼å…¥çš„é•œåƒï¼ˆå¯èƒ½æ˜¾ç¤ºä¸º<none>ï¼‰ï¼Œå¤åˆ¶å…¶IMAGE ID"
    echo "3. æ‰‹åŠ¨æ·»åŠ æ ‡ç­¾:"
    echo "   docker tag <IMAGE_ID> {expected_name}"
    echo ""
    echo "æˆ–è€…ï¼Œå¦‚æœé•œåƒå·²ç»æ­£ç¡®å¯¼å…¥å¹¶æ˜¾ç¤ºä¸º {expected_name}ï¼Œåˆ™æ— éœ€ä»»ä½•æ“ä½œã€‚"
    exit 1
fi

echo ""
echo "å¤„ç†é•œåƒ: $IMAGE_ID"

# æ£€æŸ¥é•œåƒæ˜¯å¦å·²ç»æœ‰æ­£ç¡®çš„æ ‡ç­¾
EXISTING_TAG=$(docker images --format "{{{{.Repository}}}}:{{{{.Tag}}}}" --filter "reference={expected_name}" 2>/dev/null)

if [ "$EXISTING_TAG" = "{expected_name}" ]; then
    echo "âœ… é•œåƒå·²ç»æœ‰æ­£ç¡®çš„æ ‡ç­¾: {expected_name}"
    echo "æ— éœ€è¿›è¡Œæ ‡è®°æ“ä½œã€‚"
else
    # éœ€è¦æ·»åŠ æ ‡ç­¾
    if echo "$IMAGE_ID" | grep -q "^sha256:"; then
        # è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„é•œåƒID
        echo "ä¸ºé•œåƒIDæ·»åŠ æ ‡ç­¾: $IMAGE_ID -> {expected_name}"
        if docker tag "$IMAGE_ID" "{expected_name}"; then
            echo "âœ… æ ‡è®°æˆåŠŸ!"
        else
            echo "âŒ æ ‡è®°å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ: docker tag $IMAGE_ID {expected_name}"
            exit 1
        fi
    elif [ -n "$IMAGE_ID" ]; then
        # è¿™å¯èƒ½æ˜¯ä¸€ä¸ªçŸ­IDæˆ–é•œåƒå
        echo "ä¸ºé•œåƒæ·»åŠ æ ‡ç­¾: $IMAGE_ID -> {expected_name}"
        if docker tag "$IMAGE_ID" "{expected_name}"; then
            echo "âœ… æ ‡è®°æˆåŠŸ!"
        else
            echo "âŒ æ ‡è®°å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ: docker tag $IMAGE_ID {expected_name}"
            exit 1
        fi
    fi
fi

echo ""
echo "âœ… é•œåƒå¤„ç†å®Œæˆ!"
echo "éªŒè¯ç»“æœ:"
docker images | grep "{final_image_name}" || echo "æœªæ‰¾åˆ°åŒ¹é…çš„é•œåƒï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„è¾“å‡º"
echo ""
echo "ğŸ“‹ æ€»ç»“:"
echo "- æºæ–‡ä»¶: {filename}"
echo "- ç›®æ ‡é•œåƒ: {expected_name}"
echo "- çŠ¶æ€: å·²å®Œæˆ"
"""
                        
                        try:
                            with open(script_path, 'w', encoding='utf-8') as f:
                                f.write(tag_script_content)
                            os.chmod(script_path, 0o755)  # è®¾ç½®å¯æ‰§è¡Œæƒé™
                            
                            self.emit_log(task_id, f"   ğŸ“ å·²ç”Ÿæˆæ ‡è®°è„šæœ¬: {script_name}", "success")
                            self.emit_log(task_id, f"   ä½¿ç”¨æ–¹æ³•: bash {script_name}", "info")
                        except Exception as e:
                            self.emit_log(task_id, f"   âš ï¸ ç”Ÿæˆæ ‡è®°è„šæœ¬å¤±è´¥: {e}", "warning")
                        
                        return download_url
                    else:
                        self.emit_log(task_id, f"âŒ å¯¼å‡ºçš„æ–‡ä»¶ä¸å­˜åœ¨: {file_path}", "error")
                        return False
                else:
                    self.emit_log(task_id, f"skopeoå¯¼å‡ºå‘½ä»¤å¤±è´¥ï¼Œè¿”å›ç : {process.returncode}", "error")
                    return False
                    
            except subprocess.TimeoutExpired:
                process.kill()
                self.emit_log(task_id, f"é•œåƒå¯¼å‡ºè¶…æ—¶({timeout_seconds}ç§’)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥", "error")
                return False
        
        except Exception as e:
            self.emit_log(task_id, f"å¯¼å‡ºé•œåƒ {source_image} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}", "error")
            import traceback
            self.emit_log(task_id, f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}", "error")
            return False

# åˆå§‹åŒ–ç»„ä»¶
registry_config = RegistryConfig()
image_syncer = ImageSyncer(registry_config)

# è®¤è¯ç›¸å…³è·¯ç”±
@app.route('/login')
def login():
    """ç™»å½•é¡µé¢"""
    if user_manager.is_session_valid(session):
        return redirect(url_for('index'))
    return render_template('login.html')

@app.route('/api/login', methods=['POST'])
def api_login():
    """ç™»å½•API"""
    try:
        data = request.get_json()
        username = data.get('username', '').strip()
        password = data.get('password', '')
        remember_me = data.get('remember_me', False)
        
        if not username or not password:
            return jsonify({'error': 'ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'}), 400
        
        # è·å–å®¢æˆ·ç«¯IP
        client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.environ.get('REMOTE_ADDR', ''))
        
        # éªŒè¯ç”¨æˆ·
        success, message = user_manager.authenticate(username, password, client_ip)
        
        if success:
            # è®¾ç½®ä¼šè¯
            session['username'] = username
            session['login_time'] = datetime.now().isoformat()
            session['user_agent'] = request.headers.get('User-Agent', '')
            session['client_ip'] = client_ip
            
            if remember_me:
                session_config = user_manager.config.get('session', {})
                remember_duration = session_config.get('remember_me_duration', 604800)
                session.permanent = True
                app.permanent_session_lifetime = timedelta(seconds=remember_duration)
            
            user = user_manager.get_user(username)
            logger.info(f"ç”¨æˆ· {username} ç™»å½•æˆåŠŸï¼ŒIP: {client_ip}")
            
            return jsonify({
                'success': True,
                'message': message,
                'user': {
                    'username': user['username'],
                    'display_name': user.get('display_name', username),
                    'role': user.get('role', 'user')
                }
            })
        else:
            logger.warning(f"ç”¨æˆ· {username} ç™»å½•å¤±è´¥: {message}, IP: {client_ip}")
            return jsonify({'error': message}), 401
    
    except Exception as e:
        logger.error(f"ç™»å½•å¤„ç†å¼‚å¸¸: {e}")
        return jsonify({'error': 'ç™»å½•å¤„ç†å¤±è´¥'}), 500

@app.route('/api/logout', methods=['POST'])
def api_logout():
    """ç™»å‡ºAPI"""
    username = session.get('username')
    if username:
        logger.info(f"ç”¨æˆ· {username} ç™»å‡º")
    
    session.clear()
    return jsonify({'success': True, 'message': 'å·²æˆåŠŸç™»å‡º'})

@app.route('/api/user/info')
@login_required
def get_user_info():
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    username = session.get('username')
    user = user_manager.get_user(username)
    
    if user:
        return jsonify({
            'username': user['username'],
            'display_name': user.get('display_name', username),
            'role': user.get('role', 'user'),
            'email': user.get('email', ''),
            'last_login': user.get('last_login'),
            'login_time': session.get('login_time')
        })
    else:
        return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404

@app.route('/api/user/change-password', methods=['POST'])
@login_required
def change_password():
    """ä¿®æ”¹å¯†ç """
    try:
        data = request.get_json()
        old_password = data.get('old_password', '')
        new_password = data.get('new_password', '')
        
        if not old_password or not new_password:
            return jsonify({'error': 'æ—§å¯†ç å’Œæ–°å¯†ç ä¸èƒ½ä¸ºç©º'}), 400
        
        username = session.get('username')
        user = user_manager.get_user(username)
        
        if not user:
            return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
        
        # éªŒè¯æ—§å¯†ç 
        if not user_manager.verify_password(old_password, user['password_hash']):
            return jsonify({'error': 'å½“å‰å¯†ç ä¸æ­£ç¡®'}), 401
        
        # æ£€æŸ¥æ–°å¯†ç é•¿åº¦
        security_config = user_manager.config.get('security', {})
        min_length = security_config.get('password_min_length', 6)
        
        if len(new_password) < min_length:
            return jsonify({'error': f'æ–°å¯†ç é•¿åº¦è‡³å°‘{min_length}ä¸ªå­—ç¬¦'}), 400
        
        # æ›´æ–°å¯†ç 
        new_password_hash = user_manager.hash_password(new_password)
        user_manager.config['users'][username]['password_hash'] = new_password_hash
        
        # ä¿å­˜é…ç½®
        try:
            with open(user_manager.config_file, 'w', encoding='utf-8') as f:
                yaml.dump(user_manager.config, f, allow_unicode=True, default_flow_style=False)
            
            logger.info(f"ç”¨æˆ· {username} ä¿®æ”¹å¯†ç æˆåŠŸ")
            return jsonify({'success': True, 'message': 'å¯†ç ä¿®æ”¹æˆåŠŸ'})
        
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·é…ç½®å¤±è´¥: {e}")
            return jsonify({'error': 'å¯†ç ä¿®æ”¹å¤±è´¥ï¼Œè¯·é‡è¯•'}), 500
    
    except Exception as e:
        logger.error(f"ä¿®æ”¹å¯†ç å¼‚å¸¸: {e}")
        return jsonify({'error': 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'}), 500

@app.route('/')
@login_required
def index():
    """ä¸»é¡µ"""
    return render_template('index.html')

@app.route('/debug.html')
@login_required
def debug():
    """è°ƒè¯•é¡µé¢"""
    return render_template('debug.html')

@app.route('/demo.html')
@login_required
def demo():
    """æ¼”ç¤ºé¡µé¢"""
    return render_template('demo.html')

@app.route('/admin')
@admin_required
def admin_dashboard():
    """ç®¡ç†å‘˜æ§åˆ¶é¢æ¿"""
    return render_template('admin/dashboard.html')

@app.route('/admin/users')
@admin_required
def admin_users():
    """ç”¨æˆ·ç®¡ç†é¡µé¢"""
    return render_template('admin/users.html')

@app.route('/admin/registries')
@admin_required
def admin_registries():
    """ä»“åº“ç®¡ç†é¡µé¢"""
    return render_template('admin/registries.html')

@app.route('/api/registries')
@login_required
def get_registries():
    """è·å–ç§æœåˆ—è¡¨"""
    return jsonify(registry_config.registries)

@app.route('/api/sync', methods=['POST'])
@login_required
def start_sync():
    """å¼€å§‹åŒæ­¥é•œåƒ"""
    try:
        data = request.get_json()
        images = data.get('images', [])
        target_registry = data.get('target_registry')
        target_project = data.get('target_project', '').strip()  # ç›®æ ‡é¡¹ç›®/å‘½åç©ºé—´
        replace_level = data.get('replace_level', '1')
        source_auth = data.get('source_auth')  # æºä»“åº“è®¤è¯ä¿¡æ¯
        proxy_config = data.get('proxy_config')  # ä»£ç†é…ç½®
        
        if not images:
            return jsonify({'error': 'é•œåƒåˆ—è¡¨ä¸èƒ½ä¸ºç©º'}), 400
        if not target_registry:
            return jsonify({'error': 'ç›®æ ‡ç§æœä¸èƒ½ä¸ºç©º'}), 400
        
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = f"sync_{int(time.time())}"
        
        # è®°å½•æ“ä½œæ—¥å¿—
        username = session.get('username')
        project_info = f" (é¡¹ç›®: {target_project})" if target_project else " (ä½¿ç”¨é»˜è®¤é¡¹ç›®)"
        logger.info(f"ç”¨æˆ· {username} å¯åŠ¨åŒæ­¥ä»»åŠ¡ {task_id}: {len(images)}ä¸ªé•œåƒ -> {target_registry}{project_info}")
        
        # å¯åŠ¨åŒæ­¥ä»»åŠ¡
        thread = threading.Thread(
            target=image_syncer.sync_images,
            args=(task_id, images, target_registry, replace_level, source_auth, proxy_config, target_project)
        )
        thread.start()
        
        return jsonify({'task_id': task_id, 'message': 'åŒæ­¥ä»»åŠ¡å·²å¯åŠ¨'})
    
    except Exception as e:
        logger.error(f"å¯åŠ¨åŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")
        return jsonify({'error': 'å¯åŠ¨åŒæ­¥ä»»åŠ¡å¤±è´¥'}), 500

@app.route('/api/task/<task_id>')
@login_required
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    task = sync_tasks.get(task_id)
    if task:
        return jsonify(task)
    else:
        return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

@app.route('/api/task/<task_id>/cancel', methods=['POST'])
@login_required
def cancel_task(task_id):
    """å–æ¶ˆä»»åŠ¡"""
    task = sync_tasks.get(task_id)
    if task:
        task['status'] = 'cancelled'
        username = session.get('username')
        logger.info(f"ç”¨æˆ· {username} å–æ¶ˆäº†åŒæ­¥ä»»åŠ¡ {task_id}")
        return jsonify({'message': 'ä»»åŠ¡å·²å–æ¶ˆ'})
    else:
        return jsonify({'error': 'ä»»åŠ¡ä¸å­˜åœ¨'}), 404

# æ–‡ä»¶ä¸‹è½½å’Œç®¡ç†ç›¸å…³è·¯ç”±
@app.route('/downloads/<filename>')
@login_required
def download_file(filename):
    """ä¸‹è½½å¯¼å‡ºçš„é•œåƒæ–‡ä»¶"""
    try:
        downloads_dir = 'downloads'
        file_path = os.path.join(downloads_dir, filename)
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨downloadsç›®å½•å†…
        if not os.path.abspath(file_path).startswith(os.path.abspath(downloads_dir)):
            return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„'}), 400
        
        if not os.path.exists(file_path):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # è®°å½•ä¸‹è½½æ—¥å¿—
        username = session.get('username')
        logger.info(f"ç”¨æˆ· {username} ä¸‹è½½æ–‡ä»¶: {filename}")
        
        # è¿”å›æ–‡ä»¶
        return send_file(
            file_path,
            as_attachment=True,
            download_name=filename,
            mimetype='application/x-tar'
        )
    
    except Exception as e:
        logger.error(f"ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'ä¸‹è½½å¤±è´¥'}), 500

@app.route('/api/files')
@login_required
def list_files():
    """è·å–ä¸‹è½½æ–‡ä»¶åˆ—è¡¨"""
    try:
        downloads_dir = 'downloads'
        if not os.path.exists(downloads_dir):
            return jsonify([])
        
        files = []
        scripts = {}  # ç”¨äºå­˜å‚¨å¯¹åº”çš„è„šæœ¬æ–‡ä»¶
        
        # é¦–å…ˆæ”¶é›†æ‰€æœ‰è„šæœ¬æ–‡ä»¶
        for filename in os.listdir(downloads_dir):
            if filename.startswith('tag_') and filename.endswith('.sh'):
                # æå–å¯¹åº”çš„taræ–‡ä»¶å
                # tag_é•œåƒå_æ—¶é—´æˆ³.sh -> é•œåƒå_æ—¶é—´æˆ³.tar
                script_base = filename[4:-3]  # å»æ‰ 'tag_' å‰ç¼€å’Œ '.sh' åç¼€
                tar_filename = f"{script_base}.tar"
                scripts[tar_filename] = filename
        
        for filename in os.listdir(downloads_dir):
            file_path = os.path.join(downloads_dir, filename)
            if os.path.isfile(file_path) and filename.endswith('.tar'):
                stat = os.stat(file_path)
                file_info = {
                    'name': filename,
                    'size': stat.st_size,
                    'size_mb': round(stat.st_size / (1024 * 1024), 2),
                    'created_time': datetime.fromtimestamp(stat.st_ctime).isoformat(),
                    'modified_time': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    'download_url': f'/downloads/{filename}',
                    'type': 'tar'
                }
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„æ ‡è®°è„šæœ¬
                if filename in scripts:
                    script_filename = scripts[filename]
                    script_path = os.path.join(downloads_dir, script_filename)
                    if os.path.exists(script_path):
                        file_info['script'] = {
                            'name': script_filename,
                            'download_url': f'/downloads/{script_filename}',
                            'size': os.path.getsize(script_path)
                        }
                
                files.append(file_info)
        
        # æŒ‰ä¿®æ”¹æ—¶é—´å€’åºæ’åˆ—
        files.sort(key=lambda x: x['modified_time'], reverse=True)
        
        return jsonify(files)
    
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥'}), 500

@app.route('/api/files/<filename>', methods=['DELETE'])
@login_required
def delete_file(filename):
    """åˆ é™¤ä¸‹è½½æ–‡ä»¶"""
    try:
        downloads_dir = 'downloads'
        file_path = os.path.join(downloads_dir, filename)
        
        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨downloadsç›®å½•å†…
        if not os.path.abspath(file_path).startswith(os.path.abspath(downloads_dir)):
            return jsonify({'error': 'æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„'}), 400
        
        if not os.path.exists(file_path):
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # åˆ é™¤æ–‡ä»¶
        os.remove(file_path)
        
        # è®°å½•åˆ é™¤æ—¥å¿—
        username = session.get('username')
        logger.info(f"ç”¨æˆ· {username} åˆ é™¤æ–‡ä»¶: {filename}")
        
        return jsonify({'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ é™¤å¤±è´¥'}), 500

@app.route('/api/files/cleanup', methods=['POST'])
@login_required
def cleanup_files():
    """æ¸…ç†ä¸‹è½½æ–‡ä»¶"""
    try:
        data = request.get_json() or {}
        max_age_days = data.get('max_age_days', 7)  # é»˜è®¤æ¸…ç†7å¤©å‰çš„æ–‡ä»¶
        max_files = data.get('max_files', 50)  # é»˜è®¤æœ€å¤šä¿ç•™50ä¸ªæ–‡ä»¶
        
        downloads_dir = 'downloads'
        if not os.path.exists(downloads_dir):
            return jsonify({'deleted_count': 0, 'message': 'ä¸‹è½½ç›®å½•ä¸å­˜åœ¨'})
        
        files = []
        for filename in os.listdir(downloads_dir):
            file_path = os.path.join(downloads_dir, filename)
            if os.path.isfile(file_path) and filename.endswith('.tar'):
                stat = os.stat(file_path)
                files.append({
                    'name': filename,
                    'path': file_path,
                    'mtime': stat.st_mtime
                })
        
        deleted_count = 0
        current_time = time.time()
        
        # åˆ é™¤è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶
        for file_info in files[:]:
            age_days = (current_time - file_info['mtime']) / (24 * 3600)
            if age_days > max_age_days:
                os.remove(file_info['path'])
                files.remove(file_info)
                deleted_count += 1
        
        # å¦‚æœæ–‡ä»¶æ•°é‡ä»ç„¶è¶…è¿‡é™åˆ¶ï¼Œåˆ é™¤æœ€æ—§çš„æ–‡ä»¶
        if len(files) > max_files:
            files.sort(key=lambda x: x['mtime'])
            files_to_delete = files[:len(files) - max_files]
            for file_info in files_to_delete:
                os.remove(file_info['path'])
                deleted_count += 1
        
        # è®°å½•æ¸…ç†æ—¥å¿—
        username = session.get('username')
        logger.info(f"ç”¨æˆ· {username} æ¸…ç†äº† {deleted_count} ä¸ªæ–‡ä»¶")
        
        return jsonify({
            'deleted_count': deleted_count,
            'message': f'æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶'
        })
    
    except Exception as e:
        logger.error(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': 'æ¸…ç†å¤±è´¥'}), 500

@app.route('/api/files/batch-download', methods=['POST'])
@login_required
def batch_download_files():
    """æ‰¹é‡ä¸‹è½½æ–‡ä»¶ï¼ˆæ‰“åŒ…ä¸ºzipï¼‰"""
    try:
        data = request.get_json()
        filenames = data.get('filenames', [])
        target_registry = data.get('target_registry', '')  # æ–°å¢ï¼šç›®æ ‡ä»“åº“
        
        if not filenames:
            return jsonify({'error': 'æ–‡ä»¶åˆ—è¡¨ä¸èƒ½ä¸ºç©º'}), 400
        
        downloads_dir = 'downloads'
        if not os.path.exists(downloads_dir):
            return jsonify({'error': 'ä¸‹è½½ç›®å½•ä¸å­˜åœ¨'}), 404
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶éƒ½å­˜åœ¨
        missing_files = []
        valid_files = []
        
        for filename in filenames:
            file_path = os.path.join(downloads_dir, filename)
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨downloadsç›®å½•å†…
            if not os.path.abspath(file_path).startswith(os.path.abspath(downloads_dir)):
                continue
            
            if os.path.exists(file_path):
                valid_files.append((filename, file_path))
            else:
                missing_files.append(filename)
        
        if not valid_files:
            return jsonify({'error': 'æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ–‡ä»¶'}), 404
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´ - è®¡ç®—æ€»æ–‡ä»¶å¤§å°
        total_size = sum(os.path.getsize(file_path) for _, file_path in valid_files)
        available_space = os.statvfs(downloads_dir).f_frsize * os.statvfs(downloads_dir).f_bavail
        
        if total_size * 1.5 > available_space:  # é¢„ç•™50%ç©ºé—´ç”¨äºå‹ç¼©
            return jsonify({
                'error': f'ç£ç›˜ç©ºé—´ä¸è¶³ã€‚éœ€è¦çº¦ {total_size * 1.5 / (1024*1024):.1f} MBï¼Œå¯ç”¨ {available_space / (1024*1024):.1f} MB'
            }), 507  # HTTP 507 Insufficient Storage
        
        # åˆ›å»ºä¸´æ—¶zipæ–‡ä»¶
        # ç”Ÿæˆå”¯ä¸€çš„zipæ–‡ä»¶å
        zip_filename = f"batch_download_{uuid.uuid4().hex[:8]}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
        zip_path = os.path.join(downloads_dir, zip_filename)
        
        # ç”Ÿæˆæ‰¹é‡æ¨é€è„šæœ¬
        script_filename = f"batch_push_{uuid.uuid4().hex[:8]}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sh"
        script_path = os.path.join(downloads_dir, script_filename)
        
        try:
            # åˆ›å»ºzipæ–‡ä»¶ï¼Œä½¿ç”¨æµå¼å‹ç¼©é¿å…å†…å­˜æº¢å‡ºå’Œè¶…æ—¶
            logger.info(f"å¼€å§‹åˆ›å»ºZIPæ–‡ä»¶: {zip_filename}ï¼ŒåŒ…å« {len(valid_files)} ä¸ªæ–‡ä»¶ï¼Œæ€»å¤§å°: {total_size / (1024*1024):.2f} MB")
            
            # è®¾ç½®æœ€ä½å‹ç¼©çº§åˆ«ä»¥æé«˜é€Ÿåº¦
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED, compresslevel=1) as zipf:
                for i, (filename, file_path) in enumerate(valid_files):
                    try:
                        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨
                        if not os.path.exists(file_path):
                            logger.warning(f"æ–‡ä»¶åœ¨å‹ç¼©è¿‡ç¨‹ä¸­è¢«åˆ é™¤: {filename}")
                            continue
                        
                        # è·å–æ–‡ä»¶å¤§å°ç”¨äºè¿›åº¦è®¡ç®—
                        file_size = os.path.getsize(file_path)
                        logger.info(f"æ­£åœ¨å‹ç¼©æ–‡ä»¶ ({i+1}/{len(valid_files)}): {filename} ({file_size / (1024*1024):.2f} MB)")
                        
                        # ä½¿ç”¨æµå¼æ–¹å¼æ·»åŠ å¤§æ–‡ä»¶ï¼Œé¿å…å†…å­˜æº¢å‡º
                        if file_size > 100 * 1024 * 1024:  # å¤§äº100MBçš„æ–‡ä»¶ä½¿ç”¨æµå¼å¤„ç†
                            # æ‰‹åŠ¨æ·»åŠ ZIPæ–‡ä»¶å¤´
                            info = zipfile.ZipInfo(filename)
                            info.file_size = file_size
                            info.compress_type = zipfile.ZIP_DEFLATED
                            
                            with zipf.open(info, 'w') as zf, open(file_path, 'rb') as src:
                                # åˆ†å—å†™å…¥ï¼Œæ¯æ¬¡1MB
                                chunk_size = 1024 * 1024
                                while True:
                                    chunk = src.read(chunk_size)
                                    if not chunk:
                                        break
                                    zf.write(chunk)
                        else:
                            # å°æ–‡ä»¶ç›´æ¥æ·»åŠ 
                            zipf.write(file_path, filename)
                        
                        logger.debug(f"å·²æ·»åŠ æ–‡ä»¶åˆ°ZIP: {filename}")
                        
                        # å®šæœŸæ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœæœ‰å…¶ä»–ä¿¡å·ï¼‰
                        # è¿™é‡Œå¯ä»¥æ·»åŠ ä¸­æ–­æ£€æŸ¥é€»è¾‘
                        
                    except Exception as file_error:
                        logger.error(f"æ·»åŠ æ–‡ä»¶ {filename} åˆ°ZIPæ—¶å‡ºé”™: {file_error}")
                        # ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶ï¼Œä¸ä¸­æ–­æ•´ä¸ªè¿‡ç¨‹
                        continue
            
            # éªŒè¯zipæ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if not os.path.exists(zip_path) or os.path.getsize(zip_path) == 0:
                raise Exception("ZIPæ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º")
            
            zip_size = os.path.getsize(zip_path)
            compression_ratio = (1 - zip_size / total_size) * 100 if total_size > 0 else 0
            logger.info(f"ZIPæ–‡ä»¶åˆ›å»ºæˆåŠŸ: {zip_filename}ï¼Œå¤§å°: {zip_size / (1024*1024):.2f} MBï¼Œå‹ç¼©ç‡: {compression_ratio:.1f}%")
            
            # ç”Ÿæˆæ‰¹é‡æ¨é€è„šæœ¬
            script_content = generate_batch_push_script(valid_files, target_registry)
            with open(script_path, 'w', encoding='utf-8') as f:
                f.write(script_content)
            os.chmod(script_path, 0o755)  # è®¾ç½®å¯æ‰§è¡Œæƒé™
            
            # è®°å½•æ“ä½œæ—¥å¿—
            username = session.get('username')
            logger.info(f"ç”¨æˆ· {username} åˆ›å»ºæ‰¹é‡ä¸‹è½½æ–‡ä»¶: {zip_filename}, åŒ…å« {len(valid_files)} ä¸ªæ–‡ä»¶")
            if target_registry:
                logger.info(f"ç”¨æˆ· {username} ç”Ÿæˆæ‰¹é‡æ¨é€è„šæœ¬: {script_filename}, ç›®æ ‡ä»“åº“: {target_registry}")
            
            # è¿”å›ä¸‹è½½ä¿¡æ¯
            result = {
                'zip_filename': zip_filename,
                'download_url': f'/downloads/{zip_filename}',
                'zip_size': zip_size,
                'zip_size_mb': round(zip_size / (1024*1024), 2),
                'original_size_mb': round(total_size / (1024*1024), 2),
                'compression_ratio': round(compression_ratio, 1),
                'included_files': [f[0] for f in valid_files],
                'file_count': len(valid_files),
                'script': {
                    'filename': script_filename,
                    'download_url': f'/downloads/{script_filename}',
                    'target_registry': target_registry
                }
            }
            
            if missing_files:
                result['missing_files'] = missing_files
                result['warning'] = f'æœ‰ {len(missing_files)} ä¸ªæ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå·²è·³è¿‡'
            
            return jsonify(result)
            
        except zipfile.BadZipFile as zip_error:
            logger.error(f"ZIPæ–‡ä»¶æ ¼å¼é”™è¯¯: {zip_error}")
            # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
            for cleanup_file in [zip_path, script_path]:
                if os.path.exists(cleanup_file):
                    try:
                        os.remove(cleanup_file)
                    except:
                        pass
            return jsonify({'error': 'åˆ›å»ºå‹ç¼©åŒ…æ—¶å‡ºç°æ ¼å¼é”™è¯¯ï¼Œè¯·é‡è¯•'}), 500
            
        except OSError as os_error:
            logger.error(f"æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {os_error}")
            # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
            for cleanup_file in [zip_path, script_path]:
                if os.path.exists(cleanup_file):
                    try:
                        os.remove(cleanup_file)
                    except:
                        pass
            return jsonify({'error': f'æ–‡ä»¶ç³»ç»Ÿé”™è¯¯: {str(os_error)}'}), 507
            
        except Exception as e:
            logger.error(f"åˆ›å»ºZIPè¿‡ç¨‹ä¸­çš„æœªçŸ¥é”™è¯¯: {e}")
            # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
            for cleanup_file in [zip_path, script_path]:
                if os.path.exists(cleanup_file):
                    try:
                        os.remove(cleanup_file)
                    except:
                        pass
            raise e
    
    except Exception as e:
        logger.error(f"æ‰¹é‡ä¸‹è½½å¤±è´¥: {e}")
        return jsonify({'error': f'æ‰¹é‡ä¸‹è½½å¤±è´¥: {str(e)}'}), 500

def generate_batch_push_script(valid_files, target_registry):
    """ç”Ÿæˆæ‰¹é‡æ¨é€è„šæœ¬"""
    script_content = f"""#!/bin/bash
# æ‰¹é‡é•œåƒåŠ è½½å’Œæ¨é€è„šæœ¬ - è‡ªåŠ¨ç”Ÿæˆ
# ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
# æ–‡ä»¶æ•°é‡: {len(valid_files)}
{'# ç›®æ ‡ä»“åº“: ' + target_registry if target_registry else '# ç›®æ ‡ä»“åº“: è¯·æ‰‹åŠ¨æŒ‡å®š'}

set -e  # é‡åˆ°é”™è¯¯æ—¶é€€å‡º

# é¢œè‰²è¾“å‡ºå‡½æ•°
print_info() {{
    echo -e "\\033[34m[INFO]\\033[0m $1"
}}

print_success() {{
    echo -e "\\033[32m[SUCCESS]\\033[0m $1"
}}

print_error() {{
    echo -e "\\033[31m[ERROR]\\033[0m $1"
}}

print_warning() {{
    echo -e "\\033[33m[WARNING]\\033[0m $1"
}}

# è„šæœ¬å‚æ•°è¯´æ˜
usage() {{
    echo "ç”¨æ³•: $0 [é€‰é¡¹]"
    echo ""
    echo "é€‰é¡¹:"
    echo "  -r, --registry <registry>    ç›®æ ‡ä»“åº“åœ°å€ (ä¾‹å¦‚: harbor.example.com)"
    echo "  -n, --namespace <namespace>  ç›®æ ‡å‘½åç©ºé—´ (ä¾‹å¦‚: library)"
    echo "  -u, --username <username>    ä»“åº“ç”¨æˆ·å"
    echo "  -p, --password <password>    ä»“åº“å¯†ç "
    echo "  --no-push                    åªåŠ è½½å’Œæ ‡è®°ï¼Œä¸æ¨é€"
    echo "  --dry-run                    æ¨¡æ‹Ÿè¿è¡Œï¼Œä¸å®é™…æ‰§è¡Œ"
    echo "  -h, --help                   æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯"
    echo ""
    echo "ä½¿ç”¨æ¨¡å¼:"
    echo "  1. å‘½ä»¤è¡Œå‚æ•°æ¨¡å¼ (æ¨èç”¨äºè‡ªåŠ¨åŒ–è„šæœ¬):"
    echo "     $0 -r harbor.example.com -n library -u admin -p password"
    echo ""
    echo "  2. äº¤äº’å¼è¾“å…¥æ¨¡å¼ (æ¨èç”¨äºæ‰‹åŠ¨æ“ä½œ):"
    echo "     $0"
    echo "     # è„šæœ¬ä¼šå¼•å¯¼æ‚¨è¾“å…¥ç›®æ ‡ä»“åº“åœ°å€å’Œè®¤è¯ä¿¡æ¯"
    echo ""
    echo "  3. ä»…åŠ è½½æ¨¡å¼ (ä¸æ¨é€åˆ°è¿œç¨‹ä»“åº“):"
    echo "     $0 --no-push"
    echo ""
    echo "ç¤ºä¾‹:"
    echo "  $0 -r registry.cn-hangzhou.aliyuncs.com -n mynamespace -u myuser -p mypass"
    echo "  $0 --dry-run  # æ¨¡æ‹Ÿè¿è¡Œï¼ŒæŸ¥çœ‹å°†è¦æ‰§è¡Œçš„æ“ä½œ"
    echo "  $0 --no-push  # åªåŠ è½½é•œåƒåˆ°æœ¬åœ°ï¼Œä¸æ¨é€"
}}

# é»˜è®¤å‚æ•°
TARGET_REGISTRY="{target_registry if target_registry else ''}"
TARGET_NAMESPACE="library"
USERNAME=""
PASSWORD=""
NO_PUSH=false
DRY_RUN=false

# è§£æå‘½ä»¤è¡Œå‚æ•°
while [[ $# -gt 0 ]]; do
    case $1 in
        -r|--registry)
            TARGET_REGISTRY="$2"
            shift 2
            ;;
        -n|--namespace)
            TARGET_NAMESPACE="$2"
            shift 2
            ;;
        -u|--username)
            USERNAME="$2"
            shift 2
            ;;
        -p|--password)
            PASSWORD="$2"
            shift 2
            ;;
        --no-push)
            NO_PUSH=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        -h|--help)
            usage
            exit 0
            ;;
        *)
            print_error "æœªçŸ¥å‚æ•°: $1"
            usage
            exit 1
            ;;
    esac
done

# äº¤äº’å¼è¾“å…¥ç›®æ ‡ä»“åº“ï¼ˆå¦‚æœæœªé€šè¿‡å‚æ•°æŒ‡å®šä¸”éœ€è¦æ¨é€ï¼‰
if [[ -z "$TARGET_REGISTRY" ]] && [[ "$NO_PUSH" == "false" ]]; then
    echo ""
    print_info "=== ç›®æ ‡ä»“åº“é…ç½® ==="
    echo "å½“å‰æœªæŒ‡å®šç›®æ ‡ä»“åº“åœ°å€ï¼Œè¯·é€‰æ‹©ä¸€ç§æ–¹å¼ï¼š"
    echo ""
    echo "1. è¾“å…¥ç›®æ ‡ä»“åº“åœ°å€"
    echo "2. ä»…åŠ è½½é•œåƒï¼Œä¸æ¨é€åˆ°è¿œç¨‹ä»“åº“"
    echo ""
    
    while true; do
        read -p "è¯·é€‰æ‹© (1-2): " choice
        case $choice in
            1)
                echo ""
                read -p "è¯·è¾“å…¥ç›®æ ‡ä»“åº“åœ°å€ (ä¾‹å¦‚: harbor.example.com): " TARGET_REGISTRY
                if [[ -n "$TARGET_REGISTRY" ]]; then
                    print_success "ç›®æ ‡ä»“åº“å·²è®¾ç½®ä¸º: $TARGET_REGISTRY"
                    
                    # è¯¢é—®æ˜¯å¦éœ€è¦è¾“å…¥è®¤è¯ä¿¡æ¯
                    echo ""
                    read -p "æ˜¯å¦éœ€è¦è¾“å…¥è®¤è¯ä¿¡æ¯? (y/N): " need_auth
                    if [[ "$need_auth" =~ ^[Yy] ]]; then
                        read -p "ç”¨æˆ·å: " USERNAME
                        read -s -p "å¯†ç : " PASSWORD
                        echo ""
                        print_info "è®¤è¯ä¿¡æ¯å·²è®¾ç½®"
                    fi
                    
                    # è¯¢é—®å‘½åç©ºé—´
                    echo ""
                    read -p "è¯·è¾“å…¥ç›®æ ‡å‘½åç©ºé—´ (é»˜è®¤: library): " input_namespace
                    if [[ -n "$input_namespace" ]]; then
                        TARGET_NAMESPACE="$input_namespace"
                    fi
                    
                    break
                else
                    print_error "ä»“åº“åœ°å€ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥"
                fi
                ;;
            2)
                NO_PUSH=true
                print_info "å·²è®¾ç½®ä¸ºä»…åŠ è½½æ¨¡å¼ï¼Œä¸ä¼šæ¨é€åˆ°è¿œç¨‹ä»“åº“"
                break
                ;;
            *)
                print_error "æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1 æˆ– 2"
                ;;
        esac
    done
    echo ""
fi

# éªŒè¯å¿…éœ€å‚æ•°ï¼ˆæ›´æ–°åçš„é€»è¾‘ï¼‰
if [[ -z "$TARGET_REGISTRY" ]] && [[ "$NO_PUSH" == "false" ]]; then
    print_error "è¯·é€šè¿‡ -r å‚æ•°æŒ‡å®šç›®æ ‡ä»“åº“åœ°å€ï¼Œæˆ–ä½¿ç”¨ --no-push å‚æ•°ä»…åŠ è½½é•œåƒ"
    usage
    exit 1
fi

# æ˜¾ç¤ºé…ç½®ä¿¡æ¯
print_info "=== æ‰¹é‡é•œåƒå¤„ç†é…ç½® ==="
print_info "ç›®æ ‡ä»“åº“: ${{TARGET_REGISTRY:-'æœªæŒ‡å®š'}}"
print_info "å‘½åç©ºé—´: $TARGET_NAMESPACE"
print_info "ç”¨æˆ·å: ${{USERNAME:-'æœªæŒ‡å®š'}}"
if [[ "$NO_PUSH" == "true" ]]; then
    print_info "æ¨é€æ¨¡å¼: ä»…åŠ è½½æ ‡è®°"
else
    print_info "æ¨é€æ¨¡å¼: åŠ è½½æ ‡è®°å¹¶æ¨é€"
fi
if [[ "$DRY_RUN" == "true" ]]; then
    print_info "æ‰§è¡Œæ¨¡å¼: æ¨¡æ‹Ÿè¿è¡Œ"
else
    print_info "æ‰§è¡Œæ¨¡å¼: å®é™…æ‰§è¡Œ"
fi
print_info "æ–‡ä»¶æ•°é‡: {len(valid_files)}"
echo ""

# æ£€æŸ¥Dockerå‘½ä»¤
if ! command -v docker &> /dev/null; then
    print_error "Dockerå‘½ä»¤æœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿Dockerå·²å®‰è£…å¹¶åœ¨PATHä¸­"
    exit 1
fi

# ç™»å½•åˆ°ç›®æ ‡ä»“åº“ï¼ˆå¦‚æœéœ€è¦ï¼‰
if [[ "$NO_PUSH" == "false" ]] && [[ -n "$USERNAME" ]] && [[ -n "$PASSWORD" ]]; then
    print_info "æ­£åœ¨ç™»å½•åˆ°ç›®æ ‡ä»“åº“..."
    if [[ "$DRY_RUN" == "false" ]]; then
        if echo "$PASSWORD" | docker login "$TARGET_REGISTRY" -u "$USERNAME" --password-stdin; then
            print_success "ç™»å½•æˆåŠŸ"
        else
            print_error "ç™»å½•å¤±è´¥"
            exit 1
        fi
    else
        print_info "[æ¨¡æ‹Ÿ] docker login $TARGET_REGISTRY -u $USERNAME"
    fi
    echo ""
fi

# å¤„ç†æ¯ä¸ªé•œåƒæ–‡ä»¶
PROCESSED=0
FAILED=0

"""

    # ä¸ºæ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå¤„ç†ä»£ç 
    for filename, file_path in valid_files:
        # æå–é•œåƒåç§°å’Œæ ‡ç­¾
        base_name = filename.replace('.tar', '')
        
        script_content += f"""
# å¤„ç†æ–‡ä»¶: {filename}
print_info "å¤„ç†æ–‡ä»¶: {filename}"

if [[ ! -f "{filename}" ]]; then
    print_error "æ–‡ä»¶ä¸å­˜åœ¨: {filename}"
    ((FAILED++)) || true
else
    # åŠ è½½é•œåƒ
    print_info "  æ­£åœ¨åŠ è½½é•œåƒ..."
    if [[ "$DRY_RUN" == "false" ]]; then
        LOAD_OUTPUT=$(docker load < "{filename}" 2>&1)
        if [[ $? -eq 0 ]]; then
            print_success "  é•œåƒåŠ è½½æˆåŠŸ"
            echo "    $LOAD_OUTPUT"
            
            # æå–é•œåƒIDæˆ–åç§°
            if echo "$LOAD_OUTPUT" | grep -q "Loaded image:"; then
                IMAGE_REF=$(echo "$LOAD_OUTPUT" | sed -n 's/.*Loaded image: \\(.*\\)/\\1/p')
                print_info "  æ£€æµ‹åˆ°é•œåƒ: $IMAGE_REF"
            elif echo "$LOAD_OUTPUT" | grep -q "Loaded image ID:"; then
                IMAGE_ID=$(echo "$LOAD_OUTPUT" | sed -n 's/.*Loaded image ID: sha256:\\([a-f0-9]*\\).*/\\1/p')
                IMAGE_REF="sha256:$IMAGE_ID"
                print_info "  æ£€æµ‹åˆ°é•œåƒID: $IMAGE_REF"
            else
                print_warning "  æ— æ³•è‡ªåŠ¨æ£€æµ‹é•œåƒä¿¡æ¯ï¼Œä½¿ç”¨æ–‡ä»¶åæ¨æµ‹"
                IMAGE_REF="{base_name}"
            fi
            
            # æ„å»ºç›®æ ‡é•œåƒåç§° - æ”¹è¿›çš„åç§°æ¸…ç†é€»è¾‘
            if [[ -n "$TARGET_REGISTRY" ]]; then
                # ä»æ–‡ä»¶åä¸­æå–åŸå§‹é•œåƒåç§°ï¼Œå»é™¤æ—¶é—´æˆ³
                # æ”¯æŒæ ¼å¼: redis_20250524_185515.tar -> redis:latest
                # æ”¯æŒæ ¼å¼: nginx_1.21_20250524_185515.tar -> nginx:1.21
                FILENAME_BASE=$(basename "{filename}" .tar)
                
                # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ­£åˆ™è¡¨è¾¾å¼å»é™¤æ—¶é—´æˆ³
                # åŒ¹é…æ¨¡å¼: é•œåƒå_ç‰ˆæœ¬å·_æ—¥æœŸ_æ—¶é—´ æˆ– é•œåƒå_æ—¥æœŸ_æ—¶é—´
                if [[ "$FILENAME_BASE" =~ ^(.+)_([0-9]{{8}}_[0-9]{{6}})$ ]]; then
                    # å»é™¤æ—¶é—´æˆ³éƒ¨åˆ†
                    CLEAN_NAME="${{BASH_REMATCH[1]}}"
                    print_info "  æå–çš„é•œåƒå: $CLEAN_NAME"
                    
                    # å¤„ç†é•œåƒåç§°ä¸­çš„ç‰ˆæœ¬æ ‡ç­¾
                    # å¦‚æœé•œåƒååŒ…å«ä¸‹åˆ’çº¿ï¼Œå°†æœ€åä¸€ä¸ªä¸‹åˆ’çº¿æ›¿æ¢ä¸ºå†’å·ï¼ˆä½œä¸ºæ ‡ç­¾åˆ†éš”ç¬¦ï¼‰
                    if [[ "$CLEAN_NAME" == *"_"* ]]; then
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰ˆæœ¬å·ï¼ˆæ•°å­—ã€ç‚¹ã€å­—æ¯ç­‰ï¼‰
                        if [[ "$CLEAN_NAME" =~ ^(.+)_([0-9].*|[a-z].*)$ ]]; then
                            # å¯èƒ½çš„ç‰ˆæœ¬æ ¼å¼ï¼š1.21, v1.0, alpineç­‰
                            CLEAN_NAME="${{BASH_REMATCH[1]}}:${{BASH_REMATCH[2]}}"
                            print_info "  æ£€æµ‹åˆ°ç‰ˆæœ¬æ ‡ç­¾ï¼Œæ ¼å¼åŒ–ä¸º: $CLEAN_NAME"
                        fi
                    fi
                    
                    # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œæ·»åŠ latest
                    if [[ "$CLEAN_NAME" != *":"* ]]; then
                        CLEAN_NAME="$CLEAN_NAME:latest"
                        print_info "  æ·»åŠ é»˜è®¤æ ‡ç­¾: $CLEAN_NAME"
                    fi
                else
                    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ—¶é—´æˆ³æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æ–‡ä»¶å
                    CLEAN_NAME="$FILENAME_BASE:latest"
                    print_warning "  æœªæ£€æµ‹åˆ°æ ‡å‡†æ—¶é—´æˆ³æ ¼å¼ï¼Œä½¿ç”¨æ–‡ä»¶å: $CLEAN_NAME"
                fi
                
                TARGET_IMAGE="$TARGET_REGISTRY/$TARGET_NAMESPACE/$CLEAN_NAME"
                
                print_info "  ç›®æ ‡é•œåƒ: $TARGET_IMAGE"
                
                # é‡æ–°æ ‡è®°é•œåƒ
                if docker tag "$IMAGE_REF" "$TARGET_IMAGE"; then
                    print_success "  é•œåƒæ ‡è®°æˆåŠŸ"
                    
                    # æ¨é€é•œåƒï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if [[ "$NO_PUSH" == "false" ]]; then
                        print_info "  æ­£åœ¨æ¨é€é•œåƒ..."
                        if docker push "$TARGET_IMAGE"; then
                            print_success "  é•œåƒæ¨é€æˆåŠŸ"
                        else
                            print_error "  é•œåƒæ¨é€å¤±è´¥"
                            ((FAILED++)) || true
                        fi
                    fi
                else
                    print_error "  é•œåƒæ ‡è®°å¤±è´¥"
                    ((FAILED++)) || true
                fi
            else
                print_info "  è·³è¿‡æ¨é€ï¼ˆæœªæŒ‡å®šç›®æ ‡ä»“åº“ï¼‰"
            fi
            
            ((PROCESSED++)) || true
        else
            print_error "  é•œåƒåŠ è½½å¤±è´¥: $LOAD_OUTPUT"
            ((FAILED++)) || true
        fi
    else
        # æ¨¡æ‹Ÿè¿è¡Œæ¨¡å¼ä¸‹çš„åç§°å¤„ç†é¢„è§ˆ
        FILENAME_BASE=$(basename "{filename}" .tar)
        if [[ "$FILENAME_BASE" =~ ^(.+)_([0-9]{{8}}_[0-9]{{6}})$ ]]; then
            CLEAN_NAME="${{BASH_REMATCH[1]}}"
            if [[ "$CLEAN_NAME" == *"_"* ]] && [[ "$CLEAN_NAME" =~ ^(.+)_([0-9].*|[a-z].*)$ ]]; then
                CLEAN_NAME="${{BASH_REMATCH[1]}}:${{BASH_REMATCH[2]}}"
            fi
            if [[ "$CLEAN_NAME" != *":"* ]]; then
                CLEAN_NAME="$CLEAN_NAME:latest"
            fi
        else
            CLEAN_NAME="$FILENAME_BASE:latest"
        fi
        
        print_info "  [æ¨¡æ‹Ÿ] docker load < {filename}"
        print_info "  [æ¨¡æ‹Ÿ] ç›®æ ‡é•œåƒå: $TARGET_REGISTRY/$TARGET_NAMESPACE/$CLEAN_NAME"
        print_info "  [æ¨¡æ‹Ÿ] docker tag ... $TARGET_REGISTRY/$TARGET_NAMESPACE/$CLEAN_NAME"
        if [[ "$NO_PUSH" == "false" ]]; then
            print_info "  [æ¨¡æ‹Ÿ] docker push $TARGET_REGISTRY/$TARGET_NAMESPACE/$CLEAN_NAME"
        fi
        ((PROCESSED++)) || true
    fi
fi

echo ""
"""

    # æ·»åŠ è„šæœ¬ç»“å°¾
    script_content += f"""
# å¤„ç†å®Œæˆæ€»ç»“
print_info "=== å¤„ç†å®Œæˆ ==="
print_success "æˆåŠŸå¤„ç†: $PROCESSED ä¸ªé•œåƒ"
if [[ $FAILED -gt 0 ]]; then
    print_error "å¤±è´¥: $FAILED ä¸ªé•œåƒ"
    exit 1
else
    print_success "æ‰€æœ‰é•œåƒå¤„ç†å®Œæˆï¼"
fi

# æ¸…ç†Dockerç™»å½•ä¿¡æ¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
if [[ "$NO_PUSH" == "false" ]] && [[ -n "$USERNAME" ]] && [[ "$DRY_RUN" == "false" ]]; then
    print_info "æ­£åœ¨ç™»å‡º..."
    docker logout "$TARGET_REGISTRY" 2>/dev/null || true
fi

print_info "è„šæœ¬æ‰§è¡Œå®Œæˆã€‚"
"""

    return script_content

# WebSocketäº‹ä»¶å¤„ç†
@socketio.on('connect')
def handle_connect():
    """WebSocketè¿æ¥"""
    # æ£€æŸ¥è®¤è¯çŠ¶æ€
    if not user_manager.is_session_valid(session):
        return False  # æ‹’ç»è¿æ¥
    
    username = session.get('username')
    logger.info(f"ç”¨æˆ· {username} WebSocketè¿æ¥æˆåŠŸ")
    emit('connected', {'message': 'è¿æ¥æˆåŠŸ'})

@socketio.on('disconnect')
def handle_disconnect():
    """WebSocketæ–­å¼€è¿æ¥"""
    username = session.get('username', 'unknown')
    logger.info(f"ç”¨æˆ· {username} WebSocketè¿æ¥æ–­å¼€")

@socketio.on('ping')
def handle_ping():
    """å¤„ç†å¿ƒè·³pingï¼Œè¿”å›pong"""
    emit('pong', {'timestamp': time.time()})

# æ·»åŠ è‡ªåŠ¨æ¸…ç†åŠŸèƒ½
def auto_cleanup_downloads():
    """è‡ªåŠ¨æ¸…ç†ä¸‹è½½ç›®å½•ä¸­çš„æ—§æ–‡ä»¶"""
    try:
        downloads_dir = 'downloads'
        if not os.path.exists(downloads_dir):
            logger.debug("ä¸‹è½½ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡è‡ªåŠ¨æ¸…ç†")
            return
        
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
        max_age_hours = int(os.getenv('MAX_FILE_AGE', 24))  # é»˜è®¤24å°æ—¶
        current_time = time.time()
        cleanup_count = 0
        
        logger.info(f"å¼€å§‹è‡ªåŠ¨æ¸…ç†ä¸‹è½½ç›®å½•ä¸­çš„æ—§æ–‡ä»¶... (ä¿ç•™{max_age_hours}å°æ—¶å†…çš„æ–‡ä»¶)")
        
        # è·å–æ‰€æœ‰æ–‡ä»¶
        files_to_process = []
        try:
            for filename in os.listdir(downloads_dir):
                file_path = os.path.join(downloads_dir, filename)
                if os.path.isfile(file_path):
                    try:
                        file_mtime = os.path.getmtime(file_path)
                        file_age_hours = (current_time - file_mtime) / 3600
                        files_to_process.append((filename, file_path, file_age_hours))
                    except OSError as e:
                        logger.warning(f"æ— æ³•è·å–æ–‡ä»¶ {filename} çš„ä¿®æ”¹æ—¶é—´: {e}")
                        continue
        except Exception as e:
            logger.error(f"æ— æ³•è¯»å–ä¸‹è½½ç›®å½•: {e}")
            return 0
        
        logger.info(f"å‘ç° {len(files_to_process)} ä¸ªæ–‡ä»¶å¾…æ£€æŸ¥")
        
        # æŒ‰æ–‡ä»¶å¹´é¾„æ’åº
        files_to_process.sort(key=lambda x: x[2], reverse=True)  # æœ€è€çš„æ–‡ä»¶åœ¨å‰
        
        # æ¸…ç†è¶…è¿‡æŒ‡å®šæ—¶é—´çš„æ–‡ä»¶
        for filename, file_path, file_age_hours in files_to_process:
            if file_age_hours > max_age_hours:
                try:
                    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿æ–‡ä»¶åœ¨downloadsç›®å½•å†…
                    if not os.path.abspath(file_path).startswith(os.path.abspath(downloads_dir)):
                        logger.warning(f"è·³è¿‡ä¸å®‰å…¨çš„æ–‡ä»¶è·¯å¾„: {file_path}")
                        continue
                    
                    os.remove(file_path)
                    cleanup_count += 1
                    logger.debug(f"å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {filename} (å·²å­˜åœ¨{file_age_hours:.1f}å°æ—¶)")
                    
                except Exception as e:
                    logger.warning(f"åˆ é™¤æ–‡ä»¶ {filename} å¤±è´¥: {e}")
        
        # å§‹ç»ˆè¾“å‡ºæ¸…ç†ç»“æœ
        logger.info(f"è‡ªåŠ¨æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleanup_count} ä¸ªè¿‡æœŸæ–‡ä»¶")
            
        # æ£€æŸ¥å‰©ä½™æ–‡ä»¶æ•°é‡ï¼Œå¦‚æœå¤ªå¤šåˆ™ä¿ç•™æœ€æ–°çš„100ä¸ª
        remaining_files = []
        try:
            for filename in os.listdir(downloads_dir):
                file_path = os.path.join(downloads_dir, filename)
                if os.path.isfile(file_path):
                    try:
                        file_mtime = os.path.getmtime(file_path)
                        remaining_files.append((filename, file_path, file_mtime))
                    except OSError:
                        continue
        except Exception as e:
            logger.warning(f"æ£€æŸ¥å‰©ä½™æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # å¦‚æœå‰©ä½™æ–‡ä»¶è¶…è¿‡100ä¸ªï¼Œåˆ é™¤æœ€æ—§çš„
        max_files = 100
        if len(remaining_files) > max_files:
            logger.info(f"å‘ç° {len(remaining_files)} ä¸ªæ–‡ä»¶è¶…è¿‡æœ€å¤§ä¿ç•™æ•°é‡ {max_files}ï¼Œå¼€å§‹æ¸…ç†å¤šä½™æ–‡ä»¶")
            remaining_files.sort(key=lambda x: x[2])  # æŒ‰æ—¶é—´æ’åºï¼Œæœ€æ—§åœ¨å‰
            files_to_delete = remaining_files[:len(remaining_files) - max_files]
            
            extra_cleanup_count = 0
            for filename, file_path, _ in files_to_delete:
                try:
                    os.remove(file_path)
                    extra_cleanup_count += 1
                    logger.debug(f"å·²åˆ é™¤å¤šä½™æ–‡ä»¶: {filename}")
                except Exception as e:
                    logger.warning(f"åˆ é™¤å¤šä½™æ–‡ä»¶ {filename} å¤±è´¥: {e}")
            
            if extra_cleanup_count > 0:
                logger.info(f"é¢å¤–æ¸…ç†äº† {extra_cleanup_count} ä¸ªå¤šä½™æ–‡ä»¶ï¼Œä¿ç•™æœ€æ–°çš„ {max_files} ä¸ª")
                cleanup_count += extra_cleanup_count
        
        return cleanup_count
            
    except Exception as e:
        logger.error(f"è‡ªåŠ¨æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return 0

def start_cleanup_scheduler():
    """å¯åŠ¨å®šæ—¶æ¸…ç†ä»»åŠ¡"""
    cleanup_interval = int(os.getenv('CLEANUP_INTERVAL', 6))  # é»˜è®¤6å°æ—¶
    max_age_hours = int(os.getenv('MAX_FILE_AGE', 24))  # é»˜è®¤24å°æ—¶
    schedule.every(cleanup_interval).hours.do(auto_cleanup_downloads)
    
    def run_scheduler():
        while True:
            schedule.run_pending()
            time.sleep(60)
    
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    
    # å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡æ¸…ç†
    def initial_cleanup():
        try:
            cleanup_count = auto_cleanup_downloads()
            logger.info(f"å¯åŠ¨æ—¶æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleanup_count} ä¸ªæ–‡ä»¶")
        except Exception as e:
            logger.error(f"å¯åŠ¨æ—¶æ¸…ç†å¤±è´¥: {e}")
    
    initial_cleanup_thread = threading.Thread(target=initial_cleanup, daemon=True)
    initial_cleanup_thread.start()
    
    logger.info(f"ä¸‹è½½ç›®å½•è‡ªåŠ¨æ¸…ç†è°ƒåº¦å™¨å·²å¯åŠ¨ (æ¯{cleanup_interval}å°æ—¶è¿è¡Œä¸€æ¬¡ï¼Œä¿ç•™{max_age_hours}å°æ—¶å†…æ–‡ä»¶)")

# æ‰‹åŠ¨æ¸…ç†API
@app.route('/api/files/auto-cleanup', methods=['POST'])
@login_required
def manual_auto_cleanup():
    """æ‰‹åŠ¨è§¦å‘è‡ªåŠ¨æ¸…ç†"""
    try:
        # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œæ¸…ç†
        def cleanup_task():
            try:
                cleanup_count = auto_cleanup_downloads()
                logger.info(f"æ‰‹åŠ¨æ¸…ç†å®Œæˆï¼Œåˆ é™¤äº† {cleanup_count} ä¸ªæ–‡ä»¶")
            except Exception as e:
                logger.error(f"æ‰‹åŠ¨æ¸…ç†å¤±è´¥: {e}")
        
        cleanup_thread = threading.Thread(target=cleanup_task)
        cleanup_thread.start()
        
        username = session.get('username')
        logger.info(f"ç”¨æˆ· {username} æ‰‹åŠ¨è§¦å‘äº†è‡ªåŠ¨æ¸…ç†")
        
        return jsonify({
            'success': True, 
            'message': 'è‡ªåŠ¨æ¸…ç†å·²åœ¨åå°å¯åŠ¨ï¼Œè¯·ç¨åæŸ¥çœ‹æ—¥å¿—'
        })
    
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨æ¸…ç†å¤±è´¥: {e}")
        return jsonify({'error': f'æ¸…ç†å¤±è´¥: {str(e)}'}), 500

# === ç®¡ç†å‘˜APIæ¥å£ ===

@app.route('/api/admin/users')
@admin_required
def get_all_users():
    """è·å–æ‰€æœ‰ç”¨æˆ·åˆ—è¡¨"""
    try:
        users = []
        for username, user_data in user_manager.config.get('users', {}).items():
            user_info = {
                'username': user_data['username'],
                'display_name': user_data.get('display_name', username),
                'role': user_data.get('role', 'user'),
                'email': user_data.get('email', ''),
                'active': user_data.get('active', True),
                'created_at': user_data.get('created_at', ''),
                'last_login': user_data.get('last_login', '')
            }
            users.append(user_info)
        
        return jsonify(users)
    except Exception as e:
        logger.error(f"è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥: {e}")
        return jsonify({'error': 'è·å–ç”¨æˆ·åˆ—è¡¨å¤±è´¥'}), 500

@app.route('/api/admin/users', methods=['POST'])
@admin_required
def create_user():
    """åˆ›å»ºæ–°ç”¨æˆ·"""
    try:
        data = request.get_json()
        username = data.get('username', '').strip()
        password = data.get('password', '')
        display_name = data.get('display_name', '').strip()
        email = data.get('email', '').strip()
        role = data.get('role', 'user')
        
        if not username or not password:
            return jsonify({'error': 'ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'}), 400
        
        if username in user_manager.config.get('users', {}):
            return jsonify({'error': 'ç”¨æˆ·åå·²å­˜åœ¨'}), 400
        
        # éªŒè¯å¯†ç é•¿åº¦
        security_config = user_manager.config.get('security', {})
        min_length = security_config.get('password_min_length', 6)
        if len(password) < min_length:
            return jsonify({'error': f'å¯†ç é•¿åº¦è‡³å°‘{min_length}ä¸ªå­—ç¬¦'}), 400
        
        # åˆ›å»ºç”¨æˆ·
        user_data = {
            'username': username,
            'password_hash': user_manager.hash_password(password),
            'display_name': display_name or username,
            'email': email,
            'role': role if role in ['admin', 'user'] else 'user',
            'active': True,
            'created_at': datetime.now().isoformat()
        }
        
        user_manager.config['users'][username] = user_data
        
        # ä¿å­˜é…ç½®
        with open(user_manager.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(user_manager.config, f, allow_unicode=True, default_flow_style=False)
        
        current_user = session.get('username')
        logger.info(f"ç®¡ç†å‘˜ {current_user} åˆ›å»ºäº†æ–°ç”¨æˆ·: {username}, è§’è‰²: {role}")
        
        return jsonify({'success': True, 'message': 'ç”¨æˆ·åˆ›å»ºæˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"åˆ›å»ºç”¨æˆ·å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ›å»ºç”¨æˆ·å¤±è´¥'}), 500

@app.route('/api/admin/users/<username>', methods=['PUT'])
@admin_required
def update_user(username):
    """æ›´æ–°ç”¨æˆ·ä¿¡æ¯"""
    try:
        if username not in user_manager.config.get('users', {}):
            return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
        
        data = request.get_json()
        user_data = user_manager.config['users'][username]
        
        # æ›´æ–°å…è®¸çš„å­—æ®µ
        if 'display_name' in data:
            user_data['display_name'] = data['display_name'].strip()
        if 'email' in data:
            user_data['email'] = data['email'].strip()
        if 'role' in data and data['role'] in ['admin', 'user']:
            user_data['role'] = data['role']
        if 'active' in data:
            user_data['active'] = bool(data['active'])
        
        # å¦‚æœæä¾›äº†æ–°å¯†ç ï¼Œæ›´æ–°å¯†ç 
        if data.get('password'):
            security_config = user_manager.config.get('security', {})
            min_length = security_config.get('password_min_length', 6)
            if len(data['password']) < min_length:
                return jsonify({'error': f'å¯†ç é•¿åº¦è‡³å°‘{min_length}ä¸ªå­—ç¬¦'}), 400
            user_data['password_hash'] = user_manager.hash_password(data['password'])
        
        # ä¿å­˜é…ç½®
        with open(user_manager.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(user_manager.config, f, allow_unicode=True, default_flow_style=False)
        
        current_user = session.get('username')
        logger.info(f"ç®¡ç†å‘˜ {current_user} æ›´æ–°äº†ç”¨æˆ· {username} çš„ä¿¡æ¯")
        
        return jsonify({'success': True, 'message': 'ç”¨æˆ·ä¿¡æ¯æ›´æ–°æˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"æ›´æ–°ç”¨æˆ·å¤±è´¥: {e}")
        return jsonify({'error': 'æ›´æ–°ç”¨æˆ·å¤±è´¥'}), 500

@app.route('/api/admin/users/<username>', methods=['DELETE'])
@admin_required
def delete_user(username):
    """åˆ é™¤ç”¨æˆ·"""
    try:
        if username not in user_manager.config.get('users', {}):
            return jsonify({'error': 'ç”¨æˆ·ä¸å­˜åœ¨'}), 404
        
        current_user = session.get('username')
        if username == current_user:
            return jsonify({'error': 'ä¸èƒ½åˆ é™¤è‡ªå·±çš„è´¦æˆ·'}), 400
        
        # åˆ é™¤ç”¨æˆ·
        del user_manager.config['users'][username]
        
        # ä¿å­˜é…ç½®
        with open(user_manager.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(user_manager.config, f, allow_unicode=True, default_flow_style=False)
        
        logger.info(f"ç®¡ç†å‘˜ {current_user} åˆ é™¤äº†ç”¨æˆ·: {username}")
        
        return jsonify({'success': True, 'message': 'ç”¨æˆ·åˆ é™¤æˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"åˆ é™¤ç”¨æˆ·å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ é™¤ç”¨æˆ·å¤±è´¥'}), 500

@app.route('/api/admin/registries', methods=['GET'])
@admin_required
def get_all_registries():
    """è·å–æ‰€æœ‰ä»“åº“é…ç½®"""
    return jsonify(registry_config.registries)

@app.route('/api/admin/registries', methods=['POST'])
@admin_required
def create_registry():
    """åˆ›å»ºæ–°çš„ä»“åº“é…ç½®"""
    try:
        data = request.get_json()
        
        required_fields = ['name', 'type', 'url']
        for field in required_fields:
            if not data.get(field):
                return jsonify({'error': f'{field} å­—æ®µä¸èƒ½ä¸ºç©º'}), 400
        
        # æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨
        for registry in registry_config.registries:
            if registry['name'] == data['name']:
                return jsonify({'error': 'ä»“åº“åç§°å·²å­˜åœ¨'}), 400
        
        # åˆ›å»ºæ–°çš„ä»“åº“é…ç½®
        new_registry = {
            'name': data['name'],
            'type': data['type'],
            'url': data['url'],
            'username': data.get('username', ''),
            'password': data.get('password', ''),
            'project': data.get('project', ''),
            'namespace': data.get('namespace', ''),
            'repository': data.get('repository', ''),
            'description': data.get('description', ''),
            'insecure': data.get('insecure', False),
            'active': data.get('active', True)
        }
        
        registry_config.registries.append(new_registry)
        
        # ä¿å­˜é…ç½®
        config_data = {'registries': registry_config.registries}
        with open(registry_config.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, allow_unicode=True, default_flow_style=False)
        
        current_user = session.get('username')
        logger.info(f"ç®¡ç†å‘˜ {current_user} åˆ›å»ºäº†æ–°çš„ä»“åº“é…ç½®: {data['name']}")
        
        return jsonify({'success': True, 'message': 'ä»“åº“é…ç½®åˆ›å»ºæˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"åˆ›å»ºä»“åº“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ›å»ºä»“åº“é…ç½®å¤±è´¥'}), 500

@app.route('/api/admin/registries/<int:registry_index>', methods=['PUT'])
@admin_required
def update_registry(registry_index):
    """æ›´æ–°ä»“åº“é…ç½®"""
    try:
        if registry_index >= len(registry_config.registries):
            return jsonify({'error': 'ä»“åº“é…ç½®ä¸å­˜åœ¨'}), 404
        
        data = request.get_json()
        
        required_fields = ['name', 'type', 'url']
        for field in required_fields:
            if not data.get(field):
                return jsonify({'error': f'{field} å­—æ®µä¸èƒ½ä¸ºç©º'}), 400
        
        # æ£€æŸ¥åç§°æ˜¯å¦ä¸å…¶ä»–ä»“åº“å†²çª
        for i, registry in enumerate(registry_config.registries):
            if i != registry_index and registry['name'] == data['name']:
                return jsonify({'error': 'ä»“åº“åç§°å·²å­˜åœ¨'}), 400
        
        # æ›´æ–°ä»“åº“é…ç½®
        registry_config.registries[registry_index] = {
            'name': data['name'],
            'type': data['type'],
            'url': data['url'],
            'username': data.get('username', ''),
            'password': data.get('password', ''),
            'project': data.get('project', ''),
            'namespace': data.get('namespace', ''),
            'repository': data.get('repository', ''),
            'description': data.get('description', ''),
            'insecure': data.get('insecure', False),
            'active': data.get('active', True)
        }
        
        # ä¿å­˜é…ç½®
        config_data = {'registries': registry_config.registries}
        with open(registry_config.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, allow_unicode=True, default_flow_style=False)
        
        current_user = session.get('username')
        logger.info(f"ç®¡ç†å‘˜ {current_user} æ›´æ–°äº†ä»“åº“é…ç½®: {data['name']}")
        
        return jsonify({'success': True, 'message': 'ä»“åº“é…ç½®æ›´æ–°æˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"æ›´æ–°ä»“åº“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': 'æ›´æ–°ä»“åº“é…ç½®å¤±è´¥'}), 500

@app.route('/api/admin/registries/<int:registry_index>', methods=['DELETE'])
@admin_required
def delete_registry(registry_index):
    """åˆ é™¤ä»“åº“é…ç½®"""
    try:
        if registry_index >= len(registry_config.registries):
            return jsonify({'error': 'ä»“åº“é…ç½®ä¸å­˜åœ¨'}), 404
        
        deleted_registry = registry_config.registries.pop(registry_index)
        
        # ä¿å­˜é…ç½®
        config_data = {'registries': registry_config.registries}
        with open(registry_config.config_file, 'w', encoding='utf-8') as f:
            yaml.dump(config_data, f, allow_unicode=True, default_flow_style=False)
        
        current_user = session.get('username')
        logger.info(f"ç®¡ç†å‘˜ {current_user} åˆ é™¤äº†ä»“åº“é…ç½®: {deleted_registry['name']}")
        
        return jsonify({'success': True, 'message': 'ä»“åº“é…ç½®åˆ é™¤æˆåŠŸ'})
    
    except Exception as e:
        logger.error(f"åˆ é™¤ä»“åº“é…ç½®å¤±è´¥: {e}")
        return jsonify({'error': 'åˆ é™¤ä»“åº“é…ç½®å¤±è´¥'}), 500

@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    try:
        # æ£€æŸ¥åŸºæœ¬æœåŠ¡çŠ¶æ€
        status = {
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'version': '1.0.0',
            'service': 'docker-image-sync'
        }
        
        # æ£€æŸ¥Skopeoå·¥å…·
        try:
            result = subprocess.run(['skopeo', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                status['skopeo'] = 'available'
                status['skopeo_version'] = result.stdout.strip()
            else:
                status['skopeo'] = 'unavailable'
        except Exception:
            status['skopeo'] = 'unavailable'
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_status = {}
        config_files = ['config/registries.yaml', 'config/users.yaml']
        for config_file in config_files:
            if os.path.exists(config_file):
                config_status[config_file] = 'exists'
            else:
                config_status[config_file] = 'missing'
        status['config'] = config_status
        
        # æ£€æŸ¥ç›®å½•
        directories = ['logs', 'downloads', 'templates', 'static']
        dir_status = {}
        for directory in directories:
            if os.path.exists(directory):
                dir_status[directory] = 'exists'
            else:
                dir_status[directory] = 'missing'
        status['directories'] = dir_status
        
        # æ£€æŸ¥æ´»è·ƒä»»åŠ¡
        status['active_tasks'] = len(sync_tasks)
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼ˆç®€å•æ£€æŸ¥ï¼‰
        try:
            memory = psutil.virtual_memory()
            status['memory'] = {
                'total': memory.total,
                'available': memory.available,
                'percent': memory.percent
            }
        except ImportError:
            status['memory'] = 'psutil not available'
        
        return jsonify(status), 200
        
    except Exception as e:
        error_status = {
            'status': 'unhealthy',
            'timestamp': datetime.now().isoformat(),
            'error': str(e),
            'service': 'docker-image-sync'
        }
        return jsonify(error_status), 500

@app.route('/metrics')
def metrics():
    """PrometheusæŒ‡æ ‡ç«¯ç‚¹"""
    try:
        metrics_data = []
        
        # åŸºæœ¬æŒ‡æ ‡
        metrics_data.append('# HELP docker_sync_info Application info')
        metrics_data.append('# TYPE docker_sync_info gauge')
        metrics_data.append('docker_sync_info{version="1.0.0",service="docker-image-sync"} 1')
        
        # æ´»è·ƒä»»åŠ¡æ•°
        metrics_data.append('# HELP docker_sync_active_tasks Number of active sync tasks')
        metrics_data.append('# TYPE docker_sync_active_tasks gauge')
        metrics_data.append(f'docker_sync_active_tasks {len(sync_tasks)}')
        
        # ç”¨æˆ·æ•°é‡
        user_count = len(user_manager.config.get('users', {}))
        metrics_data.append('# HELP docker_sync_users_total Total number of users')
        metrics_data.append('# TYPE docker_sync_users_total gauge')
        metrics_data.append(f'docker_sync_users_total {user_count}')
        
        # ä»“åº“é…ç½®æ•°é‡
        registry_count = len(registry_config.registries)
        metrics_data.append('# HELP docker_sync_registries_total Total number of configured registries')
        metrics_data.append('# TYPE docker_sync_registries_total gauge')
        metrics_data.append(f'docker_sync_registries_total {registry_count}')
        
        # ä¸‹è½½æ–‡ä»¶æ•°é‡
        downloads_dir = 'downloads'
        if os.path.exists(downloads_dir):
            file_count = len([f for f in os.listdir(downloads_dir) if os.path.isfile(os.path.join(downloads_dir, f))])
            metrics_data.append('# HELP docker_sync_download_files_total Total number of download files')
            metrics_data.append('# TYPE docker_sync_download_files_total gauge')
            metrics_data.append(f'docker_sync_download_files_total {file_count}')
        
        # SkopeoçŠ¶æ€
        try:
            result = subprocess.run(['skopeo', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            skopeo_status = 1 if result.returncode == 0 else 0
        except Exception:
            skopeo_status = 0
        
        metrics_data.append('# HELP docker_sync_skopeo_available Skopeo tool availability')
        metrics_data.append('# TYPE docker_sync_skopeo_available gauge')
        metrics_data.append(f'docker_sync_skopeo_available {skopeo_status}')
        
        return '\n'.join(metrics_data), 200, {'Content-Type': 'text/plain; charset=utf-8'}
        
    except Exception as e:
        return f'# Error generating metrics: {str(e)}', 500, {'Content-Type': 'text/plain; charset=utf-8'}

if __name__ == '__main__':
    # ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨
    os.makedirs('config', exist_ok=True)
    os.makedirs('templates', exist_ok=True)
    os.makedirs('static/css', exist_ok=True)
    os.makedirs('static/js', exist_ok=True)
    os.makedirs('downloads', exist_ok=True)  # åˆ›å»ºä¸‹è½½ç›®å½•
    
    # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
    if not os.path.exists('config/registries.yaml'):
        with open('config/registries.yaml', 'w', encoding='utf-8') as f:
            yaml.dump({
                'registries': registry_config.get_default_config()
            }, f, default_flow_style=False, allow_unicode=True)
    
    # å¯åŠ¨è‡ªåŠ¨æ¸…ç†è°ƒåº¦å™¨
    start_cleanup_scheduler()
    
    print("Dockeré•œåƒåŒæ­¥æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print("è®¿é—®åœ°å€: http://localhost:5000")
    print("åŠŸèƒ½ç‰¹æ€§:")
    print("  - ğŸ” ç”¨æˆ·è®¤è¯ç³»ç»Ÿ")
    print("  - ğŸ³ é•œåƒåŒæ­¥åˆ°ç§æœ")
    print("  - ğŸ“¦ å¯¼å‡ºé•œåƒä¸ºtaråŒ…")
    print("  - ğŸŒ ç½‘ç»œä»£ç†æ”¯æŒ")
    print("  - ğŸ”‘ ç§æœ‰ä»“åº“è®¤è¯")
    print("  - ğŸ“¥ æ‰¹é‡ä¸‹è½½å’Œæ¨é€è„šæœ¬")
    print("  - ğŸ§¹ è‡ªåŠ¨æ¸…ç† (ä¿ç•™1å¤©)")
    socketio.run(app, host='0.0.0.0', port=5000, debug=True) 